{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Itamarshahar/3rd_year_project2/blob/main/nlp_ex2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txgdTLBTGCbB"
      },
      "source": [
        "# NLP ex2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQoaIvQq_x-l"
      },
      "source": [
        "\n",
        "\n",
        "## import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aZ_gJ071GGvo",
        "outputId": "2d810279-73d9-4b1f-e238-4e6033c560ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.9)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the folder where plots will be saved\n",
        "output_folder = \"answers\"\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install evaluate\n",
        "\n",
        "# subset of categories that we will use\n",
        "category_dict = {'comp.graphics': 'computer graphics',\n",
        "                 'rec.sport.baseball': 'baseball',\n",
        "                 'sci.electronics': 'science, electronics',\n",
        "                 'talk.politics.guns': 'politics, guns'\n",
        "                 }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NYNZOVr_9Zb"
      },
      "source": [
        "## Helpers funcitons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0KIeDtWF9P1"
      },
      "outputs": [],
      "source": [
        "def get_data(categories=None, portion=1.):\n",
        "    \"\"\"\n",
        "    Get data for given categories and portion\n",
        "    :param portion: portion of the data to use\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # get data\n",
        "    from sklearn.datasets import fetch_20newsgroups\n",
        "    data_train = fetch_20newsgroups(categories=categories, subset='train', remove=('headers', 'footers', 'quotes'),\n",
        "                                    random_state=21)\n",
        "    data_test = fetch_20newsgroups(categories=categories, subset='test', remove=('headers', 'footers', 'quotes'),\n",
        "                                   random_state=21)\n",
        "\n",
        "    # train\n",
        "    train_len = int(portion*len(data_train.data))\n",
        "    x_train = np.array(data_train.data[:train_len])\n",
        "    y_train = data_train.target[:train_len]\n",
        "    # remove empty entries\n",
        "    non_empty = x_train != \"\"\n",
        "    x_train, y_train = x_train[non_empty].tolist(), y_train[non_empty].tolist()\n",
        "\n",
        "    # test\n",
        "    x_test = np.array(data_test.data)\n",
        "    y_test = data_test.target\n",
        "    non_empty = np.array(x_test) != \"\"\n",
        "    x_test, y_test = x_test[non_empty].tolist(), y_test[non_empty].tolist()\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "    \"\"\"\n",
        "    Get data for given categories and portion\n",
        "    :param portion: portion of the data to use\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # get data\n",
        "    from sklearn.datasets import fetch_20newsgroups\n",
        "    data_train = fetch_20newsgroups(categories=categories, subset='train', remove=('headers', 'footers', 'quotes'),\n",
        "                                    random_state=21)\n",
        "    data_test = fetch_20newsgroups(categories=categories, subset='test', remove=('headers', 'footers', 'quotes'),\n",
        "                                   random_state=21)\n",
        "\n",
        "    # train\n",
        "    train_len = int(portion*len(data_train.data))\n",
        "    x_train = np.array(data_train.data[:train_len])\n",
        "    y_train = data_train.target[:train_len]\n",
        "    # remove empty entries\n",
        "    non_empty = x_train != \"\"\n",
        "    x_train, y_train = x_train[non_empty].tolist(), y_train[non_empty].tolist()\n",
        "\n",
        "    # test\n",
        "    x_test = np.array(data_test.data)\n",
        "    y_test = data_test.target\n",
        "    non_empty = np.array(x_test) != \"\"\n",
        "    x_test, y_test = x_test[non_empty].tolist(), y_test[non_empty].tolist()\n",
        "    return x_train, y_train, x_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvlboW_zAEpC"
      },
      "source": [
        "## Q1 + Q2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSXU7vNb_q0I"
      },
      "outputs": [],
      "source": [
        "# Model for Q1,2\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.output = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.output(self.relu(self.hidden(x)))\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIVRvLKrGNeY"
      },
      "outputs": [],
      "source": [
        "def MLP_classification(portion=1., model=None):\n",
        "    \"\"\"\n",
        "    Perform classification with MLP\n",
        "    :param portion: portion of the data to use\n",
        "    :param model: PyTorch model to use\n",
        "    :return: training losses and validation accuracies\n",
        "    \"\"\"\n",
        "    x_train, y_train, x_test, y_test = get_data(\n",
        "        categories=category_dict.keys(), portion=portion)\n",
        "\n",
        "    # Vectorize the data\n",
        "    vectorizer = TfidfVectorizer(max_features=2000)\n",
        "    x_train_tfidf = vectorizer.fit_transform(x_train)\n",
        "    x_test_tfidf = vectorizer.transform(x_test)\n",
        "\n",
        "    # Convert to tensors\n",
        "    x_train_tensor = torch.tensor(x_train_tfidf.toarray(), dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "    x_test_tensor = torch.tensor(x_test_tfidf.toarray(), dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "    # Create Dataset and DataLoader\n",
        "    train_dataset = torch.utils.data.TensorDataset(x_train_tensor,\n",
        "                                                   y_train_tensor)\n",
        "    test_dataset = torch.utils.data.TensorDataset(x_test_tensor, y_test_tensor)\n",
        "\n",
        "    batch_size = 16\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                              shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Define the model\n",
        "    input_dim = x_train_tfidf.shape[1]  # Should be 2000\n",
        "    num_classes = len(category_dict)\n",
        "\n",
        "    if model is None:\n",
        "        # Default to single-layer perceptron (Q1)\n",
        "        model = nn.Linear(input_dim, num_classes)\n",
        "    else:\n",
        "        model = model  # Use the model passed in (Q2)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = 20\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * x_batch.size(0)\n",
        "\n",
        "        avg_loss = total_loss / len(train_dataset)\n",
        "        train_losses.append(avg_loss)\n",
        "\n",
        "        # Evaluate on validation data\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for x_batch, y_batch in test_loader:\n",
        "                x_batch = x_batch.to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "                outputs = model(x_batch)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += y_batch.size(0)\n",
        "                correct += (predicted == y_batch).sum().item()\n",
        "        val_accuracy = correct / total\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    return train_losses, val_accuracies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGLojAzqAgPW"
      },
      "source": [
        "## Q3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YdslIL2AbTP"
      },
      "outputs": [],
      "source": [
        "def transformer_classification(portion=1.):\n",
        "    import torch\n",
        "    from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "    from torch.utils.data import DataLoader\n",
        "    import evaluate\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    class Dataset(torch.utils.data.Dataset):\n",
        "        \"\"\"\n",
        "        Dataset for loading data\n",
        "        \"\"\"\n",
        "\n",
        "        def __init__(self, encodings, labels):\n",
        "            self.encodings = encodings\n",
        "            self.labels = labels\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = {key: torch.tensor(val[idx]) for key, val in\n",
        "                    self.encodings.items()}\n",
        "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "            return item\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.labels)\n",
        "\n",
        "    def train_epoch(model, data_loader, optimizer, dev='cpu'):\n",
        "        \"\"\"\n",
        "        Perform an epoch of training of the model with the optimizer\n",
        "        :param model:\n",
        "        :param data_loader:\n",
        "        :param optimizer:\n",
        "        :param dev:\n",
        "        :return: Average loss over the epoch\n",
        "        \"\"\"\n",
        "        model.train()\n",
        "        total_loss = 0.\n",
        "        # iterate over batches\n",
        "        for batch in tqdm(data_loader):\n",
        "            input_ids = batch['input_ids'].to(dev)\n",
        "            attention_mask = batch['attention_mask'].to(dev)\n",
        "            labels = batch['labels'].to(dev)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask,\n",
        "                            labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(data_loader)\n",
        "        return avg_loss\n",
        "\n",
        "    def evaluate_model(model, data_loader, dev='cpu', metric=None):\n",
        "        model.eval()\n",
        "        if metric is None:\n",
        "            metric = evaluate.load(\"accuracy\")\n",
        "        else:\n",
        "            metric = metric\n",
        "        for batch in tqdm(data_loader):\n",
        "            input_ids = batch['input_ids'].to(dev)\n",
        "            attention_mask = batch['attention_mask'].to(dev)\n",
        "            labels = batch['labels'].to(dev)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_ids=input_ids,\n",
        "                                attention_mask=attention_mask)\n",
        "                logits = outputs.logits\n",
        "                predictions = torch.argmax(logits, dim=-1)\n",
        "                metric.add_batch(predictions=predictions.cpu(),\n",
        "                                 references=labels.cpu())\n",
        "        return metric.compute()\n",
        "\n",
        "    x_train, y_train, x_test, y_test = get_data(\n",
        "        categories=category_dict.keys(), portion=portion)\n",
        "\n",
        "    # Parameters\n",
        "    dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    num_labels = len(category_dict)\n",
        "    epochs = 3\n",
        "    batch_size = 16\n",
        "    learning_rate = 5e-5\n",
        "\n",
        "    # Model, tokenizer, and metric\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        'distilroberta-base', num_labels=num_labels).to(dev)\n",
        "    tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')\n",
        "    metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "    # Datasets and DataLoaders\n",
        "    train_encodings = tokenizer(x_train, truncation=True, padding=True)\n",
        "    val_encodings = tokenizer(x_test, truncation=True, padding=True)\n",
        "    train_dataset = Dataset(train_encodings, y_train)\n",
        "    val_dataset = Dataset(val_encodings, y_test)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                              shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Define optimizer\n",
        "    from transformers import AdamW\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training loop\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "        avg_loss = train_epoch(model, train_loader, optimizer, dev=dev)\n",
        "        train_losses.append(avg_loss)\n",
        "        val_accuracy = evaluate_model(model, val_loader, dev=dev,\n",
        "                                      metric=metric)\n",
        "        accuracy = val_accuracy['accuracy']\n",
        "        val_accuracies.append(accuracy)\n",
        "        print(\n",
        "            f\"Average training loss: {avg_loss:.4f}, Validation accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epochs + 1), train_losses)\n",
        "    plt.title(f'Transformer Training Loss - Portion {portion}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.savefig(f'answers/Q3_portion_{portion}_loss.png')\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epochs + 1), val_accuracies)\n",
        "    plt.title(f'Transformer Validation Accuracy - Portion {portion}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.savefig(f'answers/Q3_portion_{portion}_accuracy.png')\n",
        "    plt.close()\n",
        "\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnl7DFK5Ap64"
      },
      "source": [
        "## Main run\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDI5foVXApvI"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MMJyB8B1GUeC",
        "outputId": "ba00c4ef-2c33-4511-eb91-6449061a26ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Q1 - Single Layer MLP - Portion: 0.1\n",
            "Epoch [1/20], Loss: 1.3822, Val Accuracy: 0.4907\n",
            "Epoch [2/20], Loss: 1.3567, Val Accuracy: 0.5816\n",
            "Epoch [3/20], Loss: 1.3336, Val Accuracy: 0.5968\n",
            "Epoch [4/20], Loss: 1.3108, Val Accuracy: 0.6373\n",
            "Epoch [5/20], Loss: 1.2891, Val Accuracy: 0.6412\n",
            "Epoch [6/20], Loss: 1.2670, Val Accuracy: 0.6558\n",
            "Epoch [7/20], Loss: 1.2458, Val Accuracy: 0.6684\n",
            "Epoch [8/20], Loss: 1.2251, Val Accuracy: 0.6777\n",
            "Epoch [9/20], Loss: 1.2044, Val Accuracy: 0.6771\n",
            "Epoch [10/20], Loss: 1.1844, Val Accuracy: 0.6863\n",
            "Epoch [11/20], Loss: 1.1647, Val Accuracy: 0.6883\n",
            "Epoch [12/20], Loss: 1.1452, Val Accuracy: 0.6969\n",
            "Epoch [13/20], Loss: 1.1262, Val Accuracy: 0.6983\n",
            "Epoch [14/20], Loss: 1.1075, Val Accuracy: 0.7023\n",
            "Epoch [15/20], Loss: 1.0893, Val Accuracy: 0.7029\n",
            "Epoch [16/20], Loss: 1.0712, Val Accuracy: 0.7036\n",
            "Epoch [17/20], Loss: 1.0534, Val Accuracy: 0.7129\n",
            "Epoch [18/20], Loss: 1.0360, Val Accuracy: 0.7115\n",
            "Epoch [19/20], Loss: 1.0189, Val Accuracy: 0.7115\n",
            "Epoch [20/20], Loss: 1.0024, Val Accuracy: 0.7095\n",
            "\n",
            "Q1 - Single Layer MLP - Portion: 0.2\n",
            "Epoch [1/20], Loss: 1.3752, Val Accuracy: 0.4615\n",
            "Epoch [2/20], Loss: 1.3378, Val Accuracy: 0.4927\n",
            "Epoch [3/20], Loss: 1.3035, Val Accuracy: 0.5650\n",
            "Epoch [4/20], Loss: 1.2709, Val Accuracy: 0.6021\n",
            "Epoch [5/20], Loss: 1.2391, Val Accuracy: 0.6326\n",
            "Epoch [6/20], Loss: 1.2079, Val Accuracy: 0.6499\n",
            "Epoch [7/20], Loss: 1.1778, Val Accuracy: 0.6611\n",
            "Epoch [8/20], Loss: 1.1484, Val Accuracy: 0.6731\n",
            "Epoch [9/20], Loss: 1.1205, Val Accuracy: 0.6877\n",
            "Epoch [10/20], Loss: 1.0933, Val Accuracy: 0.6976\n",
            "Epoch [11/20], Loss: 1.0668, Val Accuracy: 0.7168\n",
            "Epoch [12/20], Loss: 1.0410, Val Accuracy: 0.7182\n",
            "Epoch [13/20], Loss: 1.0161, Val Accuracy: 0.7168\n",
            "Epoch [14/20], Loss: 0.9919, Val Accuracy: 0.7281\n",
            "Epoch [15/20], Loss: 0.9681, Val Accuracy: 0.7440\n",
            "Epoch [16/20], Loss: 0.9454, Val Accuracy: 0.7414\n",
            "Epoch [17/20], Loss: 0.9233, Val Accuracy: 0.7507\n",
            "Epoch [18/20], Loss: 0.9022, Val Accuracy: 0.7473\n",
            "Epoch [19/20], Loss: 0.8813, Val Accuracy: 0.7520\n",
            "Epoch [20/20], Loss: 0.8611, Val Accuracy: 0.7566\n",
            "\n",
            "Q1 - Single Layer MLP - Portion: 0.5\n",
            "Epoch [1/20], Loss: 1.3601, Val Accuracy: 0.6983\n",
            "Epoch [2/20], Loss: 1.2944, Val Accuracy: 0.7447\n",
            "Epoch [3/20], Loss: 1.2331, Val Accuracy: 0.7659\n",
            "Epoch [4/20], Loss: 1.1754, Val Accuracy: 0.7779\n",
            "Epoch [5/20], Loss: 1.1212, Val Accuracy: 0.7924\n",
            "Epoch [6/20], Loss: 1.0701, Val Accuracy: 0.7977\n",
            "Epoch [7/20], Loss: 1.0225, Val Accuracy: 0.8064\n",
            "Epoch [8/20], Loss: 0.9776, Val Accuracy: 0.8123\n",
            "Epoch [9/20], Loss: 0.9357, Val Accuracy: 0.8137\n",
            "Epoch [10/20], Loss: 0.8966, Val Accuracy: 0.8130\n",
            "Epoch [11/20], Loss: 0.8597, Val Accuracy: 0.8163\n",
            "Epoch [12/20], Loss: 0.8254, Val Accuracy: 0.8176\n",
            "Epoch [13/20], Loss: 0.7931, Val Accuracy: 0.8183\n",
            "Epoch [14/20], Loss: 0.7627, Val Accuracy: 0.8183\n",
            "Epoch [15/20], Loss: 0.7340, Val Accuracy: 0.8203\n",
            "Epoch [16/20], Loss: 0.7072, Val Accuracy: 0.8236\n",
            "Epoch [17/20], Loss: 0.6820, Val Accuracy: 0.8223\n",
            "Epoch [18/20], Loss: 0.6581, Val Accuracy: 0.8229\n",
            "Epoch [19/20], Loss: 0.6356, Val Accuracy: 0.8210\n",
            "Epoch [20/20], Loss: 0.6143, Val Accuracy: 0.8223\n",
            "\n",
            "Q1 - Single Layer MLP - Portion: 1.0\n",
            "Epoch [1/20], Loss: 1.3342, Val Accuracy: 0.7918\n",
            "Epoch [2/20], Loss: 1.2250, Val Accuracy: 0.8097\n",
            "Epoch [3/20], Loss: 1.1282, Val Accuracy: 0.8289\n",
            "Epoch [4/20], Loss: 1.0424, Val Accuracy: 0.8316\n",
            "Epoch [5/20], Loss: 0.9663, Val Accuracy: 0.8375\n",
            "Epoch [6/20], Loss: 0.8991, Val Accuracy: 0.8389\n",
            "Epoch [7/20], Loss: 0.8394, Val Accuracy: 0.8389\n",
            "Epoch [8/20], Loss: 0.7866, Val Accuracy: 0.8395\n",
            "Epoch [9/20], Loss: 0.7392, Val Accuracy: 0.8415\n",
            "Epoch [10/20], Loss: 0.6968, Val Accuracy: 0.8442\n",
            "Epoch [11/20], Loss: 0.6587, Val Accuracy: 0.8442\n",
            "Epoch [12/20], Loss: 0.6244, Val Accuracy: 0.8455\n",
            "Epoch [13/20], Loss: 0.5932, Val Accuracy: 0.8495\n",
            "Epoch [14/20], Loss: 0.5646, Val Accuracy: 0.8495\n",
            "Epoch [15/20], Loss: 0.5385, Val Accuracy: 0.8488\n",
            "Epoch [16/20], Loss: 0.5146, Val Accuracy: 0.8515\n",
            "Epoch [17/20], Loss: 0.4925, Val Accuracy: 0.8528\n",
            "Epoch [18/20], Loss: 0.4720, Val Accuracy: 0.8521\n",
            "Epoch [19/20], Loss: 0.4530, Val Accuracy: 0.8508\n",
            "Epoch [20/20], Loss: 0.4352, Val Accuracy: 0.8528\n",
            "\n",
            "Q2 - Multi-Layer MLP - Portion: 0.1\n",
            "Epoch [1/20], Loss: 1.5415, Val Accuracy: 0.2553\n",
            "Epoch [2/20], Loss: 1.5361, Val Accuracy: 0.2553\n",
            "Epoch [3/20], Loss: 1.5312, Val Accuracy: 0.2553\n",
            "Epoch [4/20], Loss: 1.5257, Val Accuracy: 0.2553\n",
            "Epoch [5/20], Loss: 1.5206, Val Accuracy: 0.2553\n",
            "Epoch [6/20], Loss: 1.5156, Val Accuracy: 0.2553\n",
            "Epoch [7/20], Loss: 1.5108, Val Accuracy: 0.2553\n",
            "Epoch [8/20], Loss: 1.5062, Val Accuracy: 0.2553\n",
            "Epoch [9/20], Loss: 1.5012, Val Accuracy: 0.2553\n",
            "Epoch [10/20], Loss: 1.4964, Val Accuracy: 0.2553\n",
            "Epoch [11/20], Loss: 1.4921, Val Accuracy: 0.2553\n",
            "Epoch [12/20], Loss: 1.4876, Val Accuracy: 0.2553\n",
            "Epoch [13/20], Loss: 1.4833, Val Accuracy: 0.2553\n",
            "Epoch [14/20], Loss: 1.4791, Val Accuracy: 0.2553\n",
            "Epoch [15/20], Loss: 1.4749, Val Accuracy: 0.2553\n",
            "Epoch [16/20], Loss: 1.4712, Val Accuracy: 0.2553\n",
            "Epoch [17/20], Loss: 1.4674, Val Accuracy: 0.2553\n",
            "Epoch [18/20], Loss: 1.4636, Val Accuracy: 0.2553\n",
            "Epoch [19/20], Loss: 1.4602, Val Accuracy: 0.2553\n",
            "Epoch [20/20], Loss: 1.4570, Val Accuracy: 0.2553\n",
            "\n",
            "Q2 - Multi-Layer MLP - Portion: 0.2\n",
            "Epoch [1/20], Loss: 1.4829, Val Accuracy: 0.2553\n",
            "Epoch [2/20], Loss: 1.4643, Val Accuracy: 0.2599\n",
            "Epoch [3/20], Loss: 1.4449, Val Accuracy: 0.3342\n",
            "Epoch [4/20], Loss: 1.4238, Val Accuracy: 0.3521\n",
            "Epoch [5/20], Loss: 1.4033, Val Accuracy: 0.3236\n",
            "Epoch [6/20], Loss: 1.3829, Val Accuracy: 0.3084\n",
            "Epoch [7/20], Loss: 1.3622, Val Accuracy: 0.3037\n",
            "Epoch [8/20], Loss: 1.3438, Val Accuracy: 0.3037\n",
            "Epoch [9/20], Loss: 1.3240, Val Accuracy: 0.3024\n",
            "Epoch [10/20], Loss: 1.3058, Val Accuracy: 0.3349\n",
            "Epoch [11/20], Loss: 1.2883, Val Accuracy: 0.3866\n",
            "Epoch [12/20], Loss: 1.2707, Val Accuracy: 0.4423\n",
            "Epoch [13/20], Loss: 1.2535, Val Accuracy: 0.4695\n",
            "Epoch [14/20], Loss: 1.2366, Val Accuracy: 0.4794\n",
            "Epoch [15/20], Loss: 1.2205, Val Accuracy: 0.4748\n",
            "Epoch [16/20], Loss: 1.2048, Val Accuracy: 0.4728\n",
            "Epoch [17/20], Loss: 1.1891, Val Accuracy: 0.4649\n",
            "Epoch [18/20], Loss: 1.1745, Val Accuracy: 0.4715\n",
            "Epoch [19/20], Loss: 1.1599, Val Accuracy: 0.4635\n",
            "Epoch [20/20], Loss: 1.1449, Val Accuracy: 0.4509\n",
            "\n",
            "Q2 - Multi-Layer MLP - Portion: 0.5\n",
            "Epoch [1/20], Loss: 1.4004, Val Accuracy: 0.2759\n",
            "Epoch [2/20], Loss: 1.3747, Val Accuracy: 0.4218\n",
            "Epoch [3/20], Loss: 1.3528, Val Accuracy: 0.4164\n",
            "Epoch [4/20], Loss: 1.3311, Val Accuracy: 0.4098\n",
            "Epoch [5/20], Loss: 1.3102, Val Accuracy: 0.4058\n",
            "Epoch [6/20], Loss: 1.2898, Val Accuracy: 0.3946\n",
            "Epoch [7/20], Loss: 1.2697, Val Accuracy: 0.3979\n",
            "Epoch [8/20], Loss: 1.2497, Val Accuracy: 0.4092\n",
            "Epoch [9/20], Loss: 1.2299, Val Accuracy: 0.4171\n",
            "Epoch [10/20], Loss: 1.2091, Val Accuracy: 0.4105\n",
            "Epoch [11/20], Loss: 1.1894, Val Accuracy: 0.4191\n",
            "Epoch [12/20], Loss: 1.1695, Val Accuracy: 0.4171\n",
            "Epoch [13/20], Loss: 1.1499, Val Accuracy: 0.4198\n",
            "Epoch [14/20], Loss: 1.1306, Val Accuracy: 0.4284\n",
            "Epoch [15/20], Loss: 1.1117, Val Accuracy: 0.4344\n",
            "Epoch [16/20], Loss: 1.0931, Val Accuracy: 0.4549\n",
            "Epoch [17/20], Loss: 1.0749, Val Accuracy: 0.4589\n",
            "Epoch [18/20], Loss: 1.0572, Val Accuracy: 0.4702\n",
            "Epoch [19/20], Loss: 1.0403, Val Accuracy: 0.4768\n",
            "Epoch [20/20], Loss: 1.0237, Val Accuracy: 0.4920\n",
            "\n",
            "Q2 - Multi-Layer MLP - Portion: 1.0\n",
            "Epoch [1/20], Loss: 1.5413, Val Accuracy: 0.2361\n",
            "Epoch [2/20], Loss: 1.4876, Val Accuracy: 0.2361\n",
            "Epoch [3/20], Loss: 1.4071, Val Accuracy: 0.2361\n",
            "Epoch [4/20], Loss: 1.3285, Val Accuracy: 0.2361\n",
            "Epoch [5/20], Loss: 1.2585, Val Accuracy: 0.3780\n",
            "Epoch [6/20], Loss: 1.1970, Val Accuracy: 0.4556\n",
            "Epoch [7/20], Loss: 1.1436, Val Accuracy: 0.4629\n",
            "Epoch [8/20], Loss: 1.0962, Val Accuracy: 0.4768\n",
            "Epoch [9/20], Loss: 1.0547, Val Accuracy: 0.4781\n",
            "Epoch [10/20], Loss: 1.0176, Val Accuracy: 0.4914\n",
            "Epoch [11/20], Loss: 0.9846, Val Accuracy: 0.4914\n",
            "Epoch [12/20], Loss: 0.9551, Val Accuracy: 0.4914\n",
            "Epoch [13/20], Loss: 0.9286, Val Accuracy: 0.5066\n",
            "Epoch [14/20], Loss: 0.9047, Val Accuracy: 0.5133\n",
            "Epoch [15/20], Loss: 0.8830, Val Accuracy: 0.5146\n",
            "Epoch [16/20], Loss: 0.8629, Val Accuracy: 0.5252\n",
            "Epoch [17/20], Loss: 0.8446, Val Accuracy: 0.5272\n",
            "Epoch [18/20], Loss: 0.8275, Val Accuracy: 0.5312\n",
            "Epoch [19/20], Loss: 0.8115, Val Accuracy: 0.5385\n",
            "Epoch [20/20], Loss: 0.7968, Val Accuracy: 0.5464\n"
          ]
        }
      ],
      "source": [
        "portions = [0.1, 0.2, 0.5, 1.]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kKi4g7uzFG4d",
        "outputId": "0fc5983b-4df7-419b-e2fa-03b110b5705f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Q1 - Single Layer MLP - Portion: 0.1\n",
            "Epoch [1/20], Loss: 1.3825, Val Accuracy: 0.4854\n",
            "Epoch [2/20], Loss: 1.3560, Val Accuracy: 0.5710\n",
            "Epoch [3/20], Loss: 1.3327, Val Accuracy: 0.6001\n",
            "Epoch [4/20], Loss: 1.3102, Val Accuracy: 0.6300\n",
            "Epoch [5/20], Loss: 1.2882, Val Accuracy: 0.6313\n",
            "Epoch [6/20], Loss: 1.2666, Val Accuracy: 0.6340\n",
            "Epoch [7/20], Loss: 1.2449, Val Accuracy: 0.6565\n",
            "Epoch [8/20], Loss: 1.2240, Val Accuracy: 0.6638\n",
            "Epoch [9/20], Loss: 1.2036, Val Accuracy: 0.6585\n",
            "Epoch [10/20], Loss: 1.1835, Val Accuracy: 0.6718\n",
            "Epoch [11/20], Loss: 1.1638, Val Accuracy: 0.6744\n",
            "Epoch [12/20], Loss: 1.1442, Val Accuracy: 0.6744\n",
            "Epoch [13/20], Loss: 1.1249, Val Accuracy: 0.6797\n",
            "Epoch [14/20], Loss: 1.1063, Val Accuracy: 0.6844\n",
            "Epoch [15/20], Loss: 1.0879, Val Accuracy: 0.6897\n",
            "Epoch [16/20], Loss: 1.0701, Val Accuracy: 0.6963\n",
            "Epoch [17/20], Loss: 1.0522, Val Accuracy: 0.6950\n",
            "Epoch [18/20], Loss: 1.0348, Val Accuracy: 0.6976\n",
            "Epoch [19/20], Loss: 1.0177, Val Accuracy: 0.6996\n",
            "Epoch [20/20], Loss: 1.0010, Val Accuracy: 0.7016\n",
            "\n",
            "Q1 - Single Layer MLP - Portion: 0.2\n",
            "Epoch [1/20], Loss: 1.3746, Val Accuracy: 0.4821\n",
            "Epoch [2/20], Loss: 1.3369, Val Accuracy: 0.5849\n",
            "Epoch [3/20], Loss: 1.3032, Val Accuracy: 0.6273\n",
            "Epoch [4/20], Loss: 1.2698, Val Accuracy: 0.6446\n",
            "Epoch [5/20], Loss: 1.2382, Val Accuracy: 0.6333\n",
            "Epoch [6/20], Loss: 1.2067, Val Accuracy: 0.6399\n",
            "Epoch [7/20], Loss: 1.1771, Val Accuracy: 0.6505\n",
            "Epoch [8/20], Loss: 1.1483, Val Accuracy: 0.6817\n",
            "Epoch [9/20], Loss: 1.1204, Val Accuracy: 0.6804\n",
            "Epoch [10/20], Loss: 1.0933, Val Accuracy: 0.6956\n",
            "Epoch [11/20], Loss: 1.0667, Val Accuracy: 0.7076\n",
            "Epoch [12/20], Loss: 1.0414, Val Accuracy: 0.7195\n",
            "Epoch [13/20], Loss: 1.0165, Val Accuracy: 0.7248\n",
            "Epoch [14/20], Loss: 0.9924, Val Accuracy: 0.7301\n",
            "Epoch [15/20], Loss: 0.9693, Val Accuracy: 0.7367\n",
            "Epoch [16/20], Loss: 0.9465, Val Accuracy: 0.7387\n",
            "Epoch [17/20], Loss: 0.9246, Val Accuracy: 0.7440\n",
            "Epoch [18/20], Loss: 0.9035, Val Accuracy: 0.7460\n",
            "Epoch [19/20], Loss: 0.8825, Val Accuracy: 0.7447\n",
            "Epoch [20/20], Loss: 0.8623, Val Accuracy: 0.7507\n",
            "\n",
            "Q1 - Single Layer MLP - Portion: 0.5\n",
            "Epoch [1/20], Loss: 1.3589, Val Accuracy: 0.7016\n",
            "Epoch [2/20], Loss: 1.2929, Val Accuracy: 0.7275\n",
            "Epoch [3/20], Loss: 1.2317, Val Accuracy: 0.7414\n",
            "Epoch [4/20], Loss: 1.1741, Val Accuracy: 0.7692\n",
            "Epoch [5/20], Loss: 1.1197, Val Accuracy: 0.7918\n",
            "Epoch [6/20], Loss: 1.0691, Val Accuracy: 0.7997\n",
            "Epoch [7/20], Loss: 1.0212, Val Accuracy: 0.8050\n",
            "Epoch [8/20], Loss: 0.9769, Val Accuracy: 0.8017\n",
            "Epoch [9/20], Loss: 0.9349, Val Accuracy: 0.8123\n",
            "Epoch [10/20], Loss: 0.8958, Val Accuracy: 0.8150\n",
            "Epoch [11/20], Loss: 0.8589, Val Accuracy: 0.8137\n",
            "Epoch [12/20], Loss: 0.8248, Val Accuracy: 0.8156\n",
            "Epoch [13/20], Loss: 0.7925, Val Accuracy: 0.8170\n",
            "Epoch [14/20], Loss: 0.7620, Val Accuracy: 0.8190\n",
            "Epoch [15/20], Loss: 0.7337, Val Accuracy: 0.8210\n",
            "Epoch [16/20], Loss: 0.7068, Val Accuracy: 0.8223\n",
            "Epoch [17/20], Loss: 0.6815, Val Accuracy: 0.8216\n",
            "Epoch [18/20], Loss: 0.6578, Val Accuracy: 0.8223\n",
            "Epoch [19/20], Loss: 0.6353, Val Accuracy: 0.8236\n",
            "Epoch [20/20], Loss: 0.6141, Val Accuracy: 0.8216\n",
            "\n",
            "Q1 - Single Layer MLP - Portion: 1.0\n",
            "Epoch [1/20], Loss: 1.3346, Val Accuracy: 0.8156\n",
            "Epoch [2/20], Loss: 1.2250, Val Accuracy: 0.8362\n",
            "Epoch [3/20], Loss: 1.1282, Val Accuracy: 0.8362\n",
            "Epoch [4/20], Loss: 1.0423, Val Accuracy: 0.8389\n",
            "Epoch [5/20], Loss: 0.9660, Val Accuracy: 0.8382\n",
            "Epoch [6/20], Loss: 0.8987, Val Accuracy: 0.8402\n",
            "Epoch [7/20], Loss: 0.8392, Val Accuracy: 0.8402\n",
            "Epoch [8/20], Loss: 0.7863, Val Accuracy: 0.8428\n",
            "Epoch [9/20], Loss: 0.7391, Val Accuracy: 0.8408\n",
            "Epoch [10/20], Loss: 0.6966, Val Accuracy: 0.8462\n",
            "Epoch [11/20], Loss: 0.6585, Val Accuracy: 0.8488\n",
            "Epoch [12/20], Loss: 0.6242, Val Accuracy: 0.8475\n",
            "Epoch [13/20], Loss: 0.5930, Val Accuracy: 0.8508\n",
            "Epoch [14/20], Loss: 0.5645, Val Accuracy: 0.8501\n",
            "Epoch [15/20], Loss: 0.5383, Val Accuracy: 0.8508\n",
            "Epoch [16/20], Loss: 0.5144, Val Accuracy: 0.8508\n",
            "Epoch [17/20], Loss: 0.4922, Val Accuracy: 0.8521\n",
            "Epoch [18/20], Loss: 0.4717, Val Accuracy: 0.8528\n",
            "Epoch [19/20], Loss: 0.4527, Val Accuracy: 0.8515\n",
            "Epoch [20/20], Loss: 0.4350, Val Accuracy: 0.8521\n"
          ]
        }
      ],
      "source": [
        "# Q1 - single layer MLP\n",
        "for p in portions:\n",
        "  print(f\"\\nQ1 - Single Layer MLP - Portion: {p}\")\n",
        "  train_losses, val_accuracies = MLP_classification(portion=p)\n",
        "  # Plotting\n",
        "  plt.figure()\n",
        "  plt.plot(range(1,21), train_losses)\n",
        "  plt.title(f'Q1 Training Loss - Portion {p}')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.savefig(f'answers/Q1_portion_{p}_loss.png')\n",
        "  plt.close()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(range(1,21), val_accuracies)\n",
        "  plt.title(f'Q1 Validation Accuracy - Portion {p}')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.savefig(f'answers/Q1_portion_{p}_accuracy.png')\n",
        "  plt.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBv1afigFI12",
        "outputId": "0e0d5700-5dc4-43c0-80f8-7048d3dcf373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Q2 - Multi-Layer MLP - Portion: 0.1\n",
            "Epoch [1/20], Loss: 1.3757, Val Accuracy: 0.5199\n",
            "Epoch [2/20], Loss: 1.2654, Val Accuracy: 0.7109\n",
            "Epoch [3/20], Loss: 1.0454, Val Accuracy: 0.7261\n",
            "Epoch [4/20], Loss: 0.7127, Val Accuracy: 0.7407\n",
            "Epoch [5/20], Loss: 0.4031, Val Accuracy: 0.7560\n",
            "Epoch [6/20], Loss: 0.2109, Val Accuracy: 0.7546\n",
            "Epoch [7/20], Loss: 0.1158, Val Accuracy: 0.7527\n",
            "Epoch [8/20], Loss: 0.0706, Val Accuracy: 0.7527\n",
            "Epoch [9/20], Loss: 0.0490, Val Accuracy: 0.7527\n",
            "Epoch [10/20], Loss: 0.0363, Val Accuracy: 0.7513\n",
            "Epoch [11/20], Loss: 0.0288, Val Accuracy: 0.7527\n",
            "Epoch [12/20], Loss: 0.0237, Val Accuracy: 0.7520\n",
            "Epoch [13/20], Loss: 0.0200, Val Accuracy: 0.7493\n",
            "Epoch [14/20], Loss: 0.0173, Val Accuracy: 0.7473\n",
            "Epoch [15/20], Loss: 0.0152, Val Accuracy: 0.7427\n",
            "Epoch [16/20], Loss: 0.0135, Val Accuracy: 0.7414\n",
            "Epoch [17/20], Loss: 0.0122, Val Accuracy: 0.7394\n",
            "Epoch [18/20], Loss: 0.0110, Val Accuracy: 0.7394\n",
            "Epoch [19/20], Loss: 0.0100, Val Accuracy: 0.7401\n",
            "Epoch [20/20], Loss: 0.0091, Val Accuracy: 0.7394\n",
            "\n",
            "Q2 - Multi-Layer MLP - Portion: 0.2\n",
            "Epoch [1/20], Loss: 1.3540, Val Accuracy: 0.6187\n",
            "Epoch [2/20], Loss: 1.0711, Val Accuracy: 0.7825\n",
            "Epoch [3/20], Loss: 0.5788, Val Accuracy: 0.8037\n",
            "Epoch [4/20], Loss: 0.2486, Val Accuracy: 0.8044\n",
            "Epoch [5/20], Loss: 0.1153, Val Accuracy: 0.8037\n",
            "Epoch [6/20], Loss: 0.0643, Val Accuracy: 0.8057\n",
            "Epoch [7/20], Loss: 0.0424, Val Accuracy: 0.8050\n",
            "Epoch [8/20], Loss: 0.0306, Val Accuracy: 0.8037\n",
            "Epoch [9/20], Loss: 0.0238, Val Accuracy: 0.8024\n",
            "Epoch [10/20], Loss: 0.0195, Val Accuracy: 0.7984\n",
            "Epoch [11/20], Loss: 0.0164, Val Accuracy: 0.7984\n",
            "Epoch [12/20], Loss: 0.0142, Val Accuracy: 0.7977\n",
            "Epoch [13/20], Loss: 0.0125, Val Accuracy: 0.7971\n",
            "Epoch [14/20], Loss: 0.0112, Val Accuracy: 0.7964\n",
            "Epoch [15/20], Loss: 0.0101, Val Accuracy: 0.7958\n",
            "Epoch [16/20], Loss: 0.0094, Val Accuracy: 0.7938\n",
            "Epoch [17/20], Loss: 0.0085, Val Accuracy: 0.7938\n",
            "Epoch [18/20], Loss: 0.0080, Val Accuracy: 0.7938\n",
            "Epoch [19/20], Loss: 0.0075, Val Accuracy: 0.7891\n",
            "Epoch [20/20], Loss: 0.0071, Val Accuracy: 0.7931\n",
            "\n",
            "Q2 - Multi-Layer MLP - Portion: 0.5\n",
            "Epoch [1/20], Loss: 1.1716, Val Accuracy: 0.8137\n",
            "Epoch [2/20], Loss: 0.4268, Val Accuracy: 0.8382\n",
            "Epoch [3/20], Loss: 0.1548, Val Accuracy: 0.8362\n",
            "Epoch [4/20], Loss: 0.0737, Val Accuracy: 0.8302\n",
            "Epoch [5/20], Loss: 0.0425, Val Accuracy: 0.8322\n",
            "Epoch [6/20], Loss: 0.0288, Val Accuracy: 0.8282\n",
            "Epoch [7/20], Loss: 0.0220, Val Accuracy: 0.8263\n",
            "Epoch [8/20], Loss: 0.0184, Val Accuracy: 0.8269\n",
            "Epoch [9/20], Loss: 0.0159, Val Accuracy: 0.8216\n",
            "Epoch [10/20], Loss: 0.0147, Val Accuracy: 0.8236\n",
            "Epoch [11/20], Loss: 0.0136, Val Accuracy: 0.8263\n",
            "Epoch [12/20], Loss: 0.0130, Val Accuracy: 0.8229\n",
            "Epoch [13/20], Loss: 0.0126, Val Accuracy: 0.8263\n",
            "Epoch [14/20], Loss: 0.0120, Val Accuracy: 0.8229\n",
            "Epoch [15/20], Loss: 0.0118, Val Accuracy: 0.8269\n",
            "Epoch [16/20], Loss: 0.0114, Val Accuracy: 0.8276\n",
            "Epoch [17/20], Loss: 0.0114, Val Accuracy: 0.8229\n",
            "Epoch [18/20], Loss: 0.0109, Val Accuracy: 0.8236\n",
            "Epoch [19/20], Loss: 0.0113, Val Accuracy: 0.8196\n",
            "Epoch [20/20], Loss: 0.0107, Val Accuracy: 0.8223\n",
            "\n",
            "Q2 - Multi-Layer MLP - Portion: 1.0\n",
            "Epoch [1/20], Loss: 0.8763, Val Accuracy: 0.8554\n",
            "Epoch [2/20], Loss: 0.2280, Val Accuracy: 0.8488\n",
            "Epoch [3/20], Loss: 0.0958, Val Accuracy: 0.8428\n",
            "Epoch [4/20], Loss: 0.0504, Val Accuracy: 0.8442\n",
            "Epoch [5/20], Loss: 0.0322, Val Accuracy: 0.8415\n",
            "Epoch [6/20], Loss: 0.0243, Val Accuracy: 0.8375\n",
            "Epoch [7/20], Loss: 0.0206, Val Accuracy: 0.8375\n",
            "Epoch [8/20], Loss: 0.0186, Val Accuracy: 0.8355\n",
            "Epoch [9/20], Loss: 0.0173, Val Accuracy: 0.8362\n",
            "Epoch [10/20], Loss: 0.0166, Val Accuracy: 0.8362\n",
            "Epoch [11/20], Loss: 0.0161, Val Accuracy: 0.8342\n",
            "Epoch [12/20], Loss: 0.0154, Val Accuracy: 0.8316\n",
            "Epoch [13/20], Loss: 0.0155, Val Accuracy: 0.8329\n",
            "Epoch [14/20], Loss: 0.0154, Val Accuracy: 0.8342\n",
            "Epoch [15/20], Loss: 0.0155, Val Accuracy: 0.8342\n",
            "Epoch [16/20], Loss: 0.0151, Val Accuracy: 0.8342\n",
            "Epoch [17/20], Loss: 0.0152, Val Accuracy: 0.8336\n",
            "Epoch [18/20], Loss: 0.0150, Val Accuracy: 0.8355\n",
            "Epoch [19/20], Loss: 0.0148, Val Accuracy: 0.8329\n",
            "Epoch [20/20], Loss: 0.0153, Val Accuracy: 0.8355\n"
          ]
        }
      ],
      "source": [
        "# Q2 - multi-layer MLP\n",
        "for p in portions:\n",
        "  print(f\"\\nQ2 - Multi-Layer MLP - Portion: {p}\")\n",
        "  input_dim = 2000\n",
        "  hidden_dim = 500\n",
        "  num_classes = len(category_dict)\n",
        "  model = SimpleMLP(input_dim, hidden_dim, num_classes)\n",
        "  train_losses, val_accuracies = MLP_classification(portion=p, model=model)\n",
        "  # Plotting\n",
        "  plt.figure()\n",
        "  plt.plot(range(1,21), train_losses)\n",
        "  plt.title(f'Q2 Training Loss - Portion {p}')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.savefig(f'answers/Q2_portion_{p}_loss.png')\n",
        "  plt.close()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(range(1,21), val_accuracies)\n",
        "  plt.title(f'Q2 Validation Accuracy - Portion {p}')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.savefig(f'answers/Q2_portion_{p}_accuracy.png')\n",
        "  plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Oy57b6QERiM",
        "outputId": "74bb2f42-8934-415b-e261-992382684e77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Transformer results:\n",
            "Portion: 0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 15/15 [00:09<00:00,  1.52it/s]\n",
            "100%|| 95/95 [00:19<00:00,  4.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average training loss: 1.3122, Validation accuracy: 0.6598\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 15/15 [00:10<00:00,  1.49it/s]\n",
            "100%|| 95/95 [00:19<00:00,  4.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average training loss: 0.6149, Validation accuracy: 0.8123\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 15/15 [00:10<00:00,  1.46it/s]\n",
            "100%|| 95/95 [00:20<00:00,  4.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average training loss: 0.3519, Validation accuracy: 0.8574\n",
            "Portion: 0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 29/29 [00:20<00:00,  1.44it/s]\n",
            "100%|| 95/95 [00:20<00:00,  4.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average training loss: 1.0289, Validation accuracy: 0.8097\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 29/29 [00:20<00:00,  1.43it/s]\n",
            "100%|| 95/95 [00:20<00:00,  4.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average training loss: 0.3239, Validation accuracy: 0.8581\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 29/29 [00:20<00:00,  1.44it/s]\n",
            "100%|| 95/95 [00:20<00:00,  4.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average training loss: 0.1381, Validation accuracy: 0.8826\n"
          ]
        }
      ],
      "source": [
        "# Q3 - Transformer\n",
        "print(\"\\nTransformer results:\")\n",
        "for p in portions[:2]:\n",
        "  print(f\"Portion: {p}\")\n",
        "  transformer_classification(portion=p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvEYEeGWVCH3",
        "outputId": "5ede00c6-1dbe-4f70-9746-f58a27e0a285"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable Parameters:\n",
            "Log-linear Preceptron: 8004\n",
            "MLP: 1002504\n",
            "Transformer: 82121476\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import transformers\n",
        "\n",
        "# Log-linear Classifier\n",
        "def log_linear_params_with_bias(input_dim, output_dim):\n",
        "    # Weights: input_dim * output_dim\n",
        "    # Bias: output_dim (one bias for each output neuron)\n",
        "    weights = input_dim * output_dim\n",
        "    biases = output_dim\n",
        "    total_params = weights + biases\n",
        "    return total_params\n",
        "\n",
        "\n",
        "# MLP\n",
        "def mlp_params(input_dim, hidden_dim, output_dim):\n",
        "    input_to_hidden = input_dim * hidden_dim\n",
        "    hidden_to_output = hidden_dim * output_dim\n",
        "    bias_terms = hidden_dim + output_dim\n",
        "    total_params = input_to_hidden + hidden_to_output + bias_terms\n",
        "    return total_params\n",
        "\n",
        "# Transformer\n",
        "def transformer_params(model_name=\"distilroberta-base\"):\n",
        "    # Load the transformer model from Hugging Face\n",
        "    model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# Parameter calculations\n",
        "input_dim = 2000\n",
        "hidden_dim = 500\n",
        "output_dim = 4\n",
        "\n",
        "log_linear = log_linear_params_with_bias(input_dim, output_dim)\n",
        "mlp = mlp_params(input_dim, hidden_dim, output_dim)\n",
        "transformer = transformer_params()\n",
        "\n",
        "# Display the results\n",
        "print(f\"Trainable Parameters:\")\n",
        "print(f\"Log-linear Preceptron: {log_linear}\")\n",
        "print(f\"MLP: {mlp}\")\n",
        "print(f\"Transformer: {transformer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c7268f97a65e4f9598fc771b093ba1d6",
            "a79c4c66d58d46d39f8c47eca7012de1",
            "ff30053daaf34af2adedab95c182017f",
            "b695582899e24574afd9291efbc04a3c",
            "e7c91059d97345dbb343e807055a515b",
            "f239b67772ec476ca31d6369930ce534",
            "700e628f92f04d14a9b8497ec0598c41",
            "be05ec628a204ab8a4576f56bd43f941",
            "5b70e3072faa4e919b70ae4be36a301b",
            "e1adf42b0a4c4794bd46d31cc86cf708",
            "8b2c9293259f4400bfd484117e0e350e",
            "1cbb23ad46e2468aaef2a7b247bf21ad",
            "ff9178ea9c464c38aa0729083c3fd257",
            "0b438b184fc343ccb9d056714ea78b17",
            "6e8c550401b34ebc9f4abda27b087e66",
            "194eda19f5c44bd5b9e06036929befd0",
            "e02894ab20194ffcac7d48c6b400551f",
            "6df45a7322cc483db8ef616d8c6bd69b",
            "171f4fad126d4ae6a337266322df23a1",
            "36c535998b924beab1ec18effd91a74a",
            "8fbb21e09bf943899202dafeb56347d8",
            "45d9676fc9d84d4d8b3be8e61f26963d",
            "52339bf0d7b746639843cbc62f2dfa30",
            "adec4c09e7e24154af5e12225ba64f8d",
            "13c271479baf44faba08b5c17b92141b",
            "ba2915bcbb014d98af038d8b98a13fa8",
            "5d96e16a4c3b497ba1feee8e08d8736f",
            "65e4906fd5934796863f352e5ae90c33",
            "757b474584c24dbfbc1f14c40c4c2338",
            "1ae6a7a2a68b4e4d925469d64de33aa0",
            "bbe7bf5f35a64273a3fcd4d270b2a038",
            "f52f8e8a44c246d6992794922b07f7a9",
            "55bf832e97b147ae9bb036e07b2f59c3",
            "0312dfaa41b64686ae60fb1572689f2d",
            "9a2915187f5d4b2f8362b7c0a74c71a8",
            "f9bc15b7a7874e3487f1f92d36cd0d34",
            "a1182e579646422eaa2f86f9ba291ad6",
            "8ce902a31d7244b5a7eefc57dd6a02e4",
            "22f8f2326125403098e8f4be917edb72",
            "b5cc1d12347c4e8b9d843c6502d6abe6",
            "4297cf09052f458796c7c95c89c6f762",
            "1cf145481c7f4a9abfbc90f787cdf49a",
            "a9f57d7db264440ab0a7c77c098322f0",
            "d84064d3ec0e40759c78a3750bd8d30f",
            "3dfae937d51942d48ce4baefb905461b",
            "8dc99a7da0c84286bf30216e7fca2db3",
            "8ee41997f7204d9f89be2326170d7620",
            "f85fc5140a0c45ff8ad4553aeded38bc",
            "509a09eec5d74cc7a909a80e734a8da8",
            "c1666b0761ee4e329ed6351e44eff1ad",
            "640553a9a1754585a2d40c53fae87cae",
            "9c899dc14c914c3f8d69620d09e2f64c",
            "3aaa830ebfd34e3296b554713032da5a",
            "039408981637400fa52fda71be866d5f",
            "e8c6e33cc6e24313b94f986277893000",
            "0fef14c7a5fb4d36a9c68f786da279b2",
            "64d9b55d9f5743ebb4052f7b55cc4ec0",
            "6f2f4c5c98fd41b4a4d20a8549fea225",
            "d03df5cc5edb49b795c8c3597d3809e7",
            "47c0eb1966084aab8ad328dc6661545c",
            "0564a3cf2e9c480a9e26b23051809353",
            "254e0410a4c44f7eb867457623052a7c",
            "3a7e73e365bc4f51914ef9807d2bd2e1",
            "22b6083bff8c4c20949750f48e83a575",
            "3b2a2c7cecd243e19af31556fbf43d46",
            "1793d0fd51154ef5b24af7a7bcd789a5",
            "b7bcde5746bf42d3b4f7ef5bbdc2f09a",
            "98c211278daf4ef89ac703ffc7a3f537",
            "5c55c10cda124c02b0107d32c27ea06b",
            "bf2d117f68374611b2f17f569dbd27ac",
            "2fdc012519f14375b2bf3cde5063d428",
            "5e7cdcf6101341538bb0fb43c20b1182",
            "08a66672afa74e41b218c1b5fccf93da",
            "5e57440c57864ae2ba79db8d2ea867be",
            "844c4ec6b8fe474eac4ca87da5e4480c",
            "4839692b8f944b569cf79e1a908c61c4",
            "c84cbc24dcc7401aa64d0cd8e7d08e60"
          ]
        },
        "id": "H4FCwMkt576Z",
        "outputId": "569e1435-b9b3-442d-ea6c-2394c9cae931"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Transformer results:\n",
            "Portion: 0.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7268f97a65e4f9598fc771b093ba1d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1cbb23ad46e2468aaef2a7b247bf21ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52339bf0d7b746639843cbc62f2dfa30",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0312dfaa41b64686ae60fb1572689f2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3dfae937d51942d48ce4baefb905461b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fef14c7a5fb4d36a9c68f786da279b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7bcde5746bf42d3b4f7ef5bbdc2f09a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 15/15 [00:11<00:00,  1.31it/s]\n",
            "100%|| 95/95 [00:19<00:00,  4.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average training loss: 1.3557, Validation accuracy: 0.6346\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 15/15 [00:10<00:00,  1.44it/s]\n",
            "100%|| 95/95 [00:21<00:00,  4.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average training loss: 0.7329, Validation accuracy: 0.7951\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 15/15 [00:10<00:00,  1.38it/s]\n",
            "100%|| 95/95 [00:21<00:00,  4.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average training loss: 0.3156, Validation accuracy: 0.8528\n",
            "Portion: 0.2\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 29/29 [00:21<00:00,  1.37it/s]\n",
            "100%|| 95/95 [00:22<00:00,  4.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average training loss: 0.9724, Validation accuracy: 0.8223\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 29/29 [00:21<00:00,  1.38it/s]\n",
            "100%|| 95/95 [00:20<00:00,  4.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average training loss: 0.3288, Validation accuracy: 0.8528\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 29/29 [00:20<00:00,  1.39it/s]\n",
            "100%|| 95/95 [00:21<00:00,  4.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average training loss: 0.1505, Validation accuracy: 0.8747\n"
          ]
        }
      ],
      "source": [
        "###################################################\n",
        "# Exercise 2 - Natural Language Processing 67658  #\n",
        "###################################################\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# subset of categories that we will use\n",
        "category_dict = {'comp.graphics': 'computer graphics',\n",
        "                 'rec.sport.baseball': 'baseball',\n",
        "                 'sci.electronics': 'science, electronics',\n",
        "                 'talk.politics.guns': 'politics, guns'\n",
        "                 }\n",
        "\n",
        "def get_data(categories=None, portion=1.):\n",
        "    \"\"\"\n",
        "    Get data for given categories and portion\n",
        "    :param portion: portion of the data to use\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # get data\n",
        "    from sklearn.datasets import fetch_20newsgroups\n",
        "    data_train = fetch_20newsgroups(categories=categories, subset='train', remove=('headers', 'footers', 'quotes'),\n",
        "                                    random_state=21)\n",
        "    data_test = fetch_20newsgroups(categories=categories, subset='test', remove=('headers', 'footers', 'quotes'),\n",
        "                                   random_state=21)\n",
        "\n",
        "    # train\n",
        "    train_len = int(portion*len(data_train.data))\n",
        "    x_train = np.array(data_train.data[:train_len])\n",
        "    y_train = data_train.target[:train_len]\n",
        "    # remove empty entries\n",
        "    non_empty = x_train != \"\"\n",
        "    x_train, y_train = x_train[non_empty].tolist(), y_train[non_empty].tolist()\n",
        "\n",
        "    # test\n",
        "    x_test = np.array(data_test.data)\n",
        "    y_test = data_test.target\n",
        "    non_empty = np.array(x_test) != \"\"\n",
        "    x_test, y_test = x_test[non_empty].tolist(), y_test[non_empty].tolist()\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "# Model for Q2\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Q1,2\n",
        "def MLP_classification(portion=1., model=None):\n",
        "    \"\"\"\n",
        "    Perform classification with MLP\n",
        "    :param portion: portion of the data to use\n",
        "    :param model: PyTorch model to use\n",
        "    :return: training losses and validation accuracies\n",
        "    \"\"\"\n",
        "    x_train, y_train, x_test, y_test = get_data(categories=category_dict.keys(), portion=portion)\n",
        "\n",
        "    # Vectorize the data\n",
        "    vectorizer = TfidfVectorizer(max_features=2000)\n",
        "    x_train_tfidf = vectorizer.fit_transform(x_train)\n",
        "    x_test_tfidf = vectorizer.transform(x_test)\n",
        "\n",
        "    # Convert to tensors\n",
        "    x_train_tensor = torch.tensor(x_train_tfidf.toarray(), dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "    x_test_tensor = torch.tensor(x_test_tfidf.toarray(), dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "    # Create Dataset and DataLoader\n",
        "    train_dataset = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
        "    test_dataset = torch.utils.data.TensorDataset(x_test_tensor, y_test_tensor)\n",
        "\n",
        "    batch_size = 16\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Define the model\n",
        "    input_dim = x_train_tfidf.shape[1]  # Should be 2000\n",
        "    num_classes = len(category_dict)\n",
        "\n",
        "    if model is None:\n",
        "        # Default to single-layer perceptron (Q1)\n",
        "        model = nn.Linear(input_dim, num_classes)\n",
        "    else:\n",
        "        model = model  # Use the model passed in (Q2)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = 20\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * x_batch.size(0)\n",
        "\n",
        "        avg_loss = total_loss / len(train_dataset)\n",
        "        train_losses.append(avg_loss)\n",
        "\n",
        "        # Evaluate on validation data\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for x_batch, y_batch in test_loader:\n",
        "                x_batch = x_batch.to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "                outputs = model(x_batch)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += y_batch.size(0)\n",
        "                correct += (predicted == y_batch).sum().item()\n",
        "        val_accuracy = correct / total\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    return train_losses, val_accuracies\n",
        "\n",
        "# Q3\n",
        "def transformer_classification(portion=1.):\n",
        "\n",
        "    import torch\n",
        "    from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "    from torch.utils.data import DataLoader\n",
        "    import evaluate\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    class Dataset(torch.utils.data.Dataset):\n",
        "        \"\"\"\n",
        "        Dataset for loading data\n",
        "        \"\"\"\n",
        "        def __init__(self, encodings, labels):\n",
        "            self.encodings = encodings\n",
        "            self.labels = labels\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "            return item\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.labels)\n",
        "\n",
        "    def train_epoch(model, data_loader, optimizer, dev='cpu'):\n",
        "        \"\"\"\n",
        "        Perform an epoch of training of the model with the optimizer\n",
        "        :param model:\n",
        "        :param data_loader:\n",
        "        :param optimizer:\n",
        "        :param dev:\n",
        "        :return: Average loss over the epoch\n",
        "        \"\"\"\n",
        "        model.train()\n",
        "        total_loss = 0.\n",
        "        # iterate over batches\n",
        "        for batch in tqdm(data_loader):\n",
        "            input_ids = batch['input_ids'].to(dev)\n",
        "            attention_mask = batch['attention_mask'].to(dev)\n",
        "            labels = batch['labels'].to(dev)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(data_loader)\n",
        "        return avg_loss\n",
        "\n",
        "    def evaluate_model(model, data_loader, dev='cpu', metric=None):\n",
        "        model.eval()\n",
        "        if metric is None:\n",
        "            metric = evaluate.load(\"accuracy\")\n",
        "        else:\n",
        "            metric = metric\n",
        "        for batch in tqdm(data_loader):\n",
        "            input_ids = batch['input_ids'].to(dev)\n",
        "            attention_mask = batch['attention_mask'].to(dev)\n",
        "            labels = batch['labels'].to(dev)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits\n",
        "                predictions = torch.argmax(logits, dim=-1)\n",
        "                metric.add_batch(predictions=predictions.cpu(), references=labels.cpu())\n",
        "        return metric.compute()\n",
        "\n",
        "    x_train, y_train, x_test, y_test = get_data(categories=category_dict.keys(), portion=portion)\n",
        "\n",
        "    # Parameters\n",
        "    dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    num_labels = len(category_dict)\n",
        "    epochs = 3\n",
        "    batch_size = 16\n",
        "    learning_rate = 5e-5\n",
        "\n",
        "    # Model, tokenizer, and metric\n",
        "    model = AutoModelForSequenceClassification.from_pretrained('distilroberta-base', num_labels=num_labels).to(dev)\n",
        "    tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')\n",
        "    metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "    # Datasets and DataLoaders\n",
        "    train_encodings = tokenizer(x_train, truncation=True, padding=True)\n",
        "    val_encodings = tokenizer(x_test, truncation=True, padding=True)\n",
        "    train_dataset = Dataset(train_encodings, y_train)\n",
        "    val_dataset = Dataset(val_encodings, y_test)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Define optimizer\n",
        "    from transformers import AdamW\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training loop\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        avg_loss = train_epoch(model, train_loader, optimizer, dev=dev)\n",
        "        train_losses.append(avg_loss)\n",
        "        val_accuracy = evaluate_model(model, val_loader, dev=dev, metric=metric)\n",
        "        accuracy = val_accuracy['accuracy']\n",
        "        val_accuracies.append(accuracy)\n",
        "        print(f\"Average training loss: {avg_loss:.4f}, Validation accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epochs+1), train_losses)\n",
        "    plt.title(f'Transformer Training Loss - Portion {portion}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.savefig(f'Q3_portion_{portion}_loss.png')\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epochs+1), val_accuracies)\n",
        "    plt.title(f'Transformer Validation Accuracy - Portion {portion}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.savefig(f'Q3_portion_{portion}_accuracy.png')\n",
        "    plt.close()\n",
        "\n",
        "    return\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    portions = [0.1, 0.2, 0.5, 1.]\n",
        "\n",
        "    # # Q1 - single layer MLP\n",
        "    # for p in portions:\n",
        "    #     print(f\"\\nQ1 - Single Layer MLP - Portion: {p}\")\n",
        "    #     train_losses, val_accuracies = MLP_classification(portion=p)\n",
        "    #     # Plotting\n",
        "    #     plt.figure()\n",
        "    #     plt.plot(range(1,21), train_losses)\n",
        "    #     plt.title(f'Q1 Training Loss - Portion {p}')\n",
        "    #     plt.xlabel('Epoch')\n",
        "    #     plt.ylabel('Loss')\n",
        "    #     plt.savefig(f'Q1_portion_{p}_loss.png')\n",
        "    #     plt.close()\n",
        "\n",
        "    #     plt.figure()\n",
        "    #     plt.plot(range(1,21), val_accuracies)\n",
        "    #     plt.title(f'Q1 Validation Accuracy - Portion {p}')\n",
        "    #     plt.xlabel('Epoch')\n",
        "    #     plt.ylabel('Accuracy')\n",
        "    #     plt.savefig(f'Q1_portion_{p}_accuracy.png')\n",
        "    #     plt.close()\n",
        "\n",
        "    # # Q2 - multi-layer MLP\n",
        "    # for p in portions:\n",
        "    #     print(f\"\\nQ2 - Multi-Layer MLP - Portion: {p}\")\n",
        "    #     input_dim = 2000\n",
        "    #     hidden_dim = 500\n",
        "    #     num_classes = len(category_dict)\n",
        "    #     model = SimpleMLP(input_dim, hidden_dim, num_classes)\n",
        "    #     train_losses, val_accuracies = MLP_classification(portion=p, model=model)\n",
        "    #     # Plotting\n",
        "    #     plt.figure()\n",
        "    #     plt.plot(range(1,21), train_losses)\n",
        "    #     plt.title(f'Q2 Training Loss - Portion {p}')\n",
        "    #     plt.xlabel('Epoch')\n",
        "    #     plt.ylabel('Loss')\n",
        "    #     plt.savefig(f'Q2_portion_{p}_loss.png')\n",
        "    #     plt.close()\n",
        "\n",
        "    #     plt.figure()\n",
        "    #     plt.plot(range(1,21), val_accuracies)\n",
        "    #     plt.title(f'Q2 Validation Accuracy - Portion {p}')\n",
        "    #     plt.xlabel('Epoch')\n",
        "    #     plt.ylabel('Accuracy')\n",
        "    #     plt.savefig(f'Q2_portion_{p}_accuracy.png')\n",
        "    #     plt.close()\n",
        "\n",
        "    # Q3 - Transformer\n",
        "    print(\"\\nTransformer results:\")\n",
        "    for p in portions[:2]:\n",
        "        print(f\"Portion: {p}\")\n",
        "        transformer_classification(portion=p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxzkasPm-KQG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnbTAtV8ccVC"
      },
      "source": [
        "# NLP ex4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-xZNqNHBcDF"
      },
      "source": [
        "## data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3a_dmQTBeD1",
        "outputId": "873e3238-dd52-4941-ea39-1e122a0bc71d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[just too silly and sophomoric to ensnare its target audience . | Negative | 0.29167, there is n't one moment in the film that surprises or delights . | Negative | 0.16667]\n",
            "0.29167\n",
            "['just', 'too', 'silly', 'and', 'sophomoric', 'to', 'ensnare', 'its', 'target', 'audience']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "POSITIVE_SENTIMENT = 1.\n",
        "NEGATIVE_SENTIMENT = 0.\n",
        "NEUTRAL_SENTIMENT = -1.\n",
        "\n",
        "\n",
        "SENTIMENT_NAMES = {\n",
        "    POSITIVE_SENTIMENT: \"Positive\",\n",
        "    NEUTRAL_SENTIMENT: \"Neutral\",\n",
        "    NEGATIVE_SENTIMENT: \"Negative\"\n",
        "}\n",
        "SENTS_PATH = \"SOStr.txt\"\n",
        "TREES_PATH = \"STree.txt\"\n",
        "DICT_PATH = \"dictionary.txt\"\n",
        "LABELS_path = \"sentiment_labels.txt\"\n",
        "\n",
        "\n",
        "def get_sentiment_class_from_val(sentiment_val: float):\n",
        "    if sentiment_val <= 0.4:\n",
        "        return NEGATIVE_SENTIMENT\n",
        "    elif sentiment_val >= 0.6:\n",
        "        return POSITIVE_SENTIMENT\n",
        "    else:\n",
        "        return NEUTRAL_SENTIMENT\n",
        "\n",
        "class SentimentTreeNode(object):\n",
        "    def __init__(self, text: list, sentiment_val: float, min_token_idx: int, children=[], parent=None):\n",
        "        self.text = text\n",
        "        self.sentiment_val = sentiment_val\n",
        "        self.min_token_idx = min_token_idx\n",
        "        self.sentiment_class = get_sentiment_class_from_val(sentiment_val)\n",
        "        self.children = children\n",
        "        self.parent = parent\n",
        "\n",
        "\n",
        "class Sentence(object):\n",
        "    \"\"\"\n",
        "    Represents a sentence in sentiment tree bank.\n",
        "    You can access the sentence text by sent.text\n",
        "    This will give you a list of tokens (strings) in the order that they appear in the sentence.\n",
        "    sent.sentiment_class is the coding of the annotated sentiment polarity of the sentence.\n",
        "    sent.sentiment_val is the exact annotated sentiment value in the range [0,1]\n",
        "    \"\"\"\n",
        "    def __init__(self, sentence_root: SentimentTreeNode):\n",
        "        self.root = sentence_root\n",
        "        self.text = sentence_root.text\n",
        "        self.sentiment_class = sentence_root.sentiment_class\n",
        "        self.sentiment_val = sentence_root.sentiment_val\n",
        "\n",
        "    def _get_leaves_recursively(self, cur_root):\n",
        "        if len(cur_root.children) == 0:\n",
        "            return [cur_root]\n",
        "        else:\n",
        "            cur_leaves = []\n",
        "            for child in cur_root.children:\n",
        "                cur_leaves += self._get_leaves_recursively(child)\n",
        "            return cur_leaves\n",
        "\n",
        "    def get_leaves(self):\n",
        "        return self._get_leaves_recursively(self.root)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \" \".join(self.text) + \" | \" + SENTIMENT_NAMES[self.sentiment_class] + \" | \" + str(self.sentiment_val)\n",
        "\n",
        "\n",
        "class SentimentTreeBank(object):\n",
        "    \"\"\"\n",
        "    The main object that represents the stanfordSentimentTreeBank dataset. Can be used to access the\n",
        "    examples and some other utilities.\n",
        "    \"\"\"\n",
        "    def __init__(self, path=\"stanfordSentimentTreebank\", split_ratios=(0.8,0.1,0.1), split_words=True):\n",
        "        \"\"\"\n",
        "\n",
        "        :param path: relative or absolute path to the datset directory\n",
        "        :param split_ratios: split ratios for train, validation and test. please do not change!\n",
        "        :param split_words: whether to split tokens with \"-\" and \"/\" symbols. please do not change!\n",
        "        \"\"\"\n",
        "        self._base_path = path\n",
        "        self.split_words = split_words\n",
        "        sentences = self._read_sentences()\n",
        "        self.sentences = self._build_dataset(sentences)\n",
        "        if self.split_words:\n",
        "            for sent in self.sentences:\n",
        "                leaves = sent.get_leaves()\n",
        "                for node in leaves:\n",
        "                    node_text = node.text\n",
        "                    splitted = node_text[0].split(\"-\")\n",
        "                    splitted_final = []\n",
        "                    for s in splitted:\n",
        "                        splitted_final.extend(s.split(\"\\\\/\"))\n",
        "                    if len(splitted_final) > 1 and all([len(s) > 0 for s in splitted_final]):\n",
        "                        leaves = [SentimentTreeNode([s], node.sentiment_val,\n",
        "                                                    min_token_idx=node.min_token_idx, parent=node) for\n",
        "                                  s in splitted_final]\n",
        "                        node.text = splitted_final\n",
        "                        node.children = leaves\n",
        "                        cur_parent = node.parent\n",
        "                        while cur_parent != None:\n",
        "                            cur_parent.text = []\n",
        "                            for child in cur_parent.children:\n",
        "                                cur_parent.text.extend(child.text)\n",
        "                            cur_parent = cur_parent.parent\n",
        "                sent.text = sent.root.text\n",
        "\n",
        "\n",
        "        assert len(split_ratios) == 3\n",
        "        assert sum(split_ratios) == 1\n",
        "        self.split_ratios = split_ratios\n",
        "\n",
        "\n",
        "\n",
        "    def _read_sentences(self):\n",
        "        sentences = []\n",
        "        with open(os.path.join(self._base_path, SENTS_PATH), \"r\", encoding=\"utf-8\") as f:\n",
        "            lines = f.read().split(\"\\n\")\n",
        "            for i, line in enumerate(lines):\n",
        "                if len(line.strip()) == 0:\n",
        "                    continue\n",
        "                line_content = line.strip()\n",
        "                tokens = line_content.split(\"|\")\n",
        "                tokens = [t.lower().replace(\"-lrb-\",\"(\").replace(\"-rrb-\", \")\") for t in tokens]\n",
        "                sentences.append(tokens)\n",
        "        return sentences\n",
        "\n",
        "    def _build_dataset(self, sentences):\n",
        "        phrases_dictionary = {}\n",
        "\n",
        "        # extract phrases\n",
        "        with open(os.path.join(self._base_path, DICT_PATH), \"r\", encoding=\"utf-8\") as f:\n",
        "            lines = f.read().split(\"\\n\")[:-1]\n",
        "            for line in lines:\n",
        "                phrase, phrase_id = line.strip().split(\"|\")\n",
        "                phrases_dictionary[phrase.lower().replace(\"-lrb-\",\"(\").replace(\"-rrb-\", \")\")] = int(phrase_id)\n",
        "\n",
        "        # extract labels\n",
        "        with open(os.path.join(self._base_path, LABELS_path), \"r\",  encoding=\"utf-8\") as f:\n",
        "            lines = [l.strip().split(\"|\") for l in f.read().split(\"\\n\")[1:-1]]\n",
        "            labels_dict = {int(l[0]): float(l[1]) for l in lines}\n",
        "\n",
        "\n",
        "        def get_val_from_phrase(phrase_tokens_list):\n",
        "            try:\n",
        "                return labels_dict[phrases_dictionary[\" \".join(phrase_tokens_list)]]\n",
        "            except:\n",
        "                print(\"couldn't find key!\")\n",
        "\n",
        "        # load the sentences tree structures\n",
        "        tree_pointers = []\n",
        "        with open(os.path.join(self._base_path, TREES_PATH), \"r\") as f:\n",
        "            for line in f.readlines():\n",
        "                sent_pointers = [int(p) for p in line.strip().split(\"|\")]\n",
        "                tree_pointers.append(sent_pointers)\n",
        "        assert len(tree_pointers) == len(sentences)\n",
        "\n",
        "        # create Sentence instances with tree of SentimentTreeNodes\n",
        "        labeled_sentences = []\n",
        "        for sent, sent_pointers in zip(sentences, tree_pointers):\n",
        "            try:\n",
        "\n",
        "                children_dict = {i: [] for i in range(len(sent_pointers))}\n",
        "                for i, p in enumerate(sent_pointers):\n",
        "                    if i < len(sent):\n",
        "                        node_text = [sent[i]]\n",
        "                        node = SentimentTreeNode(text=node_text, sentiment_val=get_val_from_phrase(node_text),\n",
        "                                                 min_token_idx=i)\n",
        "                    else:\n",
        "                        children = children_dict[i]\n",
        "                        children = sorted(children, key= lambda n: n.min_token_idx)\n",
        "                        node_text = []\n",
        "                        for child in children:\n",
        "                            node_text.extend(child.text)\n",
        "                        node = SentimentTreeNode(text=node_text, sentiment_val=get_val_from_phrase(node_text),\n",
        "                                                 children=children, min_token_idx=children[0].min_token_idx)\n",
        "                        for child in children:\n",
        "                            child.parent = node\n",
        "                    if p > 0:\n",
        "                        children_dict[p - 1].append(node)\n",
        "                    last_node = node\n",
        "                new_sentence = Sentence(last_node)\n",
        "                if new_sentence.sentiment_class == NEUTRAL_SENTIMENT:\n",
        "                    continue\n",
        "                labeled_sentences.append(new_sentence)\n",
        "            except Exception as e:\n",
        "                raise e\n",
        "                print(\"couldn't parse sentence!\")\n",
        "                print(sent)\n",
        "        random.Random(1).shuffle(labeled_sentences) # shuffle but with the same shuffle each time\n",
        "        return labeled_sentences\n",
        "\n",
        "    def get_train_set(self):\n",
        "        \"\"\"\n",
        "        :return: list of Sentence instances for the train part of the dataset\n",
        "        \"\"\"\n",
        "        if not hasattr(self, \"_train_set\"):\n",
        "            self._train_set = self.sentences[:int(self.split_ratios[0] * len(self.sentences))]\n",
        "        return self._train_set\n",
        "\n",
        "    def _extract_all_phrases(self, root):\n",
        "        phrases = [Sentence(root)] if root.sentiment_class != NEUTRAL_SENTIMENT else []\n",
        "        if len(root.text) == 1:\n",
        "            return []\n",
        "        for child in root.children:\n",
        "            phrases += self._extract_all_phrases(child)\n",
        "        return phrases\n",
        "\n",
        "    def get_train_set_phrases(self):\n",
        "        \"\"\"\n",
        "        :return: list of Sentence instances for the train part of the dataset including all sub-phrases\n",
        "        \"\"\"\n",
        "        if not hasattr(self, \"_train_set_phrases\"):\n",
        "            train_set = self.get_train_set()\n",
        "            train_set_phrases = []\n",
        "            for sent in train_set:\n",
        "                train_set_phrases += self._extract_all_phrases(sent.root)\n",
        "            self._train_set_phrases = train_set_phrases\n",
        "        return self._train_set_phrases\n",
        "\n",
        "    def get_test_set(self):\n",
        "        \"\"\"\n",
        "        :return: list of Sentence instances for the test part of the dataset\n",
        "        \"\"\"\n",
        "        if not hasattr(self, \"_test_set\"):\n",
        "            begin_index = int(self.split_ratios[0] * len(self.sentences))\n",
        "            end_index = int(sum(self.split_ratios[:2]) * len(self.sentences))\n",
        "            self._test_set = self.sentences[begin_index:end_index]\n",
        "        return self._test_set\n",
        "\n",
        "    def get_validation_set(self):\n",
        "        \"\"\"\n",
        "        :return: list of Sentence instances for the validation part of the dataset\n",
        "        \"\"\"\n",
        "        if not hasattr(self, \"_validation_set\"):\n",
        "            self._validation_set = self.sentences[int(sum(self.split_ratios[:2]) * len(self.sentences)):]\n",
        "        return self._validation_set\n",
        "\n",
        "    def get_train_word_counts(self):\n",
        "        \"\"\"\n",
        "        :return: dictionary of all words in the train set with their frequency in the train set.\n",
        "        \"\"\"\n",
        "        if not hasattr(self, \"_train_word_counts\"):\n",
        "            word_counts = {}\n",
        "            for sent in self.get_train_set():\n",
        "                for word_node in sent.get_leaves():\n",
        "                    assert len(word_node.text) == 1\n",
        "                    word_text = word_node.text[0]\n",
        "                    if word_text in word_counts:\n",
        "                        word_counts[word_text] += 1\n",
        "                    else:\n",
        "                        word_counts[word_text] = 1\n",
        "            self._train_word_counts = word_counts\n",
        "\n",
        "        return self._train_word_counts\n",
        "\n",
        "    def get_word_counts(self):\n",
        "        \"\"\"\n",
        "        :return: dictionary of all words in the dataset with their frequency in the whole dataset.\n",
        "        \"\"\"\n",
        "        if not hasattr(self, \"_word_counts\"):\n",
        "            word_counts = {}\n",
        "            for sent in self.sentences:\n",
        "                for word_node in sent.get_leaves():\n",
        "                    assert len(word_node.text) == 1\n",
        "                    word_text = word_node.text[0]\n",
        "                    if word_text in word_counts:\n",
        "                        word_counts[word_text] += 1\n",
        "                    else:\n",
        "                        word_counts[word_text] = 1\n",
        "            self._word_counts = word_counts\n",
        "\n",
        "        return self._word_counts\n",
        "\n",
        "\n",
        "\n",
        "def get_negated_polarity_examples(sentences_list, num_examples=None, choose_random=False):\n",
        "    \"\"\"\n",
        "    Returns the indices of the sentences in sentences_list which have subphrase in the second level with\n",
        "    sentiment polarity different than the whole sentence polarity.\n",
        "    :param sentences_list: list of Sentence objects\n",
        "    :param num_examples: number of examples to return, if None all of them are returned\n",
        "    :param choose_random: relevant only if num_examples is lower than the number of exisitng negated\n",
        "    polarity examples in sentences_list\n",
        "    \"\"\"\n",
        "\n",
        "    if num_examples is None:\n",
        "        num_examples = len(sentences_list) # take all possible sentences\n",
        "\n",
        "    def is_polarized(sent: Sentence):\n",
        "        if sent.sentiment_class == NEUTRAL_SENTIMENT:\n",
        "            return False\n",
        "        else:\n",
        "            root_polarity = sent.sentiment_class\n",
        "            for child in sent.root.children:\n",
        "                if child.sentiment_class == 1 - root_polarity:\n",
        "                    return True\n",
        "            return False\n",
        "    indexed_senteces = list(enumerate(sentences_list))\n",
        "    negated_sentences = list(filter(lambda s: is_polarized(s[1]), indexed_senteces))\n",
        "    negated_sentences_indices = [i for i,s in negated_sentences]\n",
        "    if len(negated_sentences) <= num_examples:\n",
        "        return negated_sentences_indices\n",
        "    else:\n",
        "        if choose_random:\n",
        "            random.shuffle(negated_sentences_indices)\n",
        "        return negated_sentences_indices[:num_examples]\n",
        "\n",
        "\n",
        "def get_sentiment_words(sent: Sentence):\n",
        "    sent_polarity = sent.sentiment_class\n",
        "    return [node for node in sent.get_leaves() if node.sentiment_class == sent_polarity]\n",
        "\n",
        "\n",
        "def get_rare_words_examples(sentences_list, dataset: SentimentTreeBank,\n",
        "                            num_sentences=50):\n",
        "    \"\"\"\n",
        "    Computes for each sentence in sentences the maximal train frequency of sentiment word, where sentiment\n",
        "    word is a word which is labeled with either positive or negative sentiment value, and returns the\n",
        "    indices of the <num_sentences> sentences with lowest value.\n",
        "    :param sentences_list: list of Sentence objects\n",
        "    :param dataset: the SentimentTreebank datset object\n",
        "    :param num_sentences: number of sentences to return\n",
        "    :return: list of ints representing the indices of the chosen sentences out of the input sentences_list\n",
        "    \"\"\"\n",
        "    word_counts = dataset.get_train_word_counts()\n",
        "\n",
        "    def get_count(word_node: SentimentTreeNode):\n",
        "        word_text = word_node.text[0]\n",
        "        if word_text in word_counts:\n",
        "            return word_counts[word_text]\n",
        "        else:\n",
        "            return 0\n",
        "    indexed_sentences = list(enumerate(sentences_list))\n",
        "    indexed_sentences = list(filter(lambda s: len(get_sentiment_words(s[1])) > 0, indexed_sentences))\n",
        "    indexed_sentences = sorted(indexed_sentences, key= lambda s: max([get_count(node) for node in\n",
        "                                                                      get_sentiment_words(s[1])]))\n",
        "    indices = [i for i,s in indexed_sentences]\n",
        "    return indices[:num_sentences]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # examples for reading the sentiment dataset\n",
        "    dataset = SentimentTreeBank()\n",
        "    # get train set\n",
        "    print(dataset.get_train_set()[:2])\n",
        "    print(dataset.get_train_set()[0].sentiment_val)\n",
        "    # get word counts dictionary\n",
        "    print(list(dataset.get_word_counts().keys())[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DWzxYyGCJPj"
      },
      "source": [
        "## Imports and consts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ykOOJxoFcO84"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "import operator\n",
        "import pickle\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Iterable, Tuple, Dict\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW, get_scheduler, AutoTokenizer\n",
        "import torch\n",
        "# import torch.optim.AdamW\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
        "from transformers import get_scheduler\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xxca2ryxA3rH"
      },
      "outputs": [],
      "source": [
        "SEQ_LEN = 52\n",
        "W2V_EMBEDDING_DIM = 300\n",
        "\n",
        "RARE_WORDS = \"rare_words\"\n",
        "ONEHOT_AVERAGE = \"onehot_average\"\n",
        "W2V_AVERAGE = \"w2v_average\"\n",
        "W2V_SEQUENCE = \"w2v_sequence\"\n",
        "NEGATIVE_POLARITY = \"negative_polarity\"\n",
        "TRAIN = \"train\"\n",
        "VAL = \"val\"\n",
        "TEST = \"test\"\n",
        "ACCURACY = \"accuracy\"\n",
        "VALIDATION = \"validation\"\n",
        "LOSS = \"loss\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ycJZpFsA_PH"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "th0fXGMIA-E1"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------ Models ----------------------------------------------------\n",
        "class LSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    An LSTM for sentiment analysis with architecture as described in the exercise description.\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_dim, hidden_dim, n_layers, dropout):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim,\n",
        "                    bidirectional=True, dropout=dropout, num_layers=n_layers, dtype=torch.float64, batch_first=True)\n",
        "        self.linear1 = nn.Linear(hidden_dim * 2, 1, bias=True, dtype=torch.float64)\n",
        "    def forward(self, text):\n",
        "        lstm_out, _ = self.lstm(text)\n",
        "        lstm_out = torch.cat((lstm_out[:, -1, :self.hidden_dim], lstm_out[:, 0, self.hidden_dim:]), dim=1) # first and last\n",
        "        return self.linear1(lstm_out)\n",
        "\n",
        "\n",
        "    def predict(self, text):\n",
        "        with torch.no_grad():\n",
        "            return torch.sigmoid(self.forward(text))\n",
        "\n",
        "class LogLinear(nn.Module):\n",
        "    \"\"\"\n",
        "    general class for the log-linear models for sentiment analysis.\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_dim):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(embedding_dim, 1, bias=True, dtype=torch.float64)\n",
        "        # Add device attribute and move the model to the device\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear1(x)\n",
        "\n",
        "    def predict(self, x): #TODO validate logits?\n",
        "        # Move input to the model's device\n",
        "        x = x.to(self.device)\n",
        "        with torch.no_grad():\n",
        "            return torch.sigmoid(self.forward(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXeUCB9ueeiO"
      },
      "source": [
        "## Training functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VA1EU6Hetho"
      },
      "source": [
        "### Training Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KfTFF14rGIo9"
      },
      "outputs": [],
      "source": [
        "def get_available_device():\n",
        "    \"\"\"\n",
        "    Allows training on GPU if available. Can help with running things faster when a GPU with cuda is\n",
        "    available but not a most...\n",
        "    Given a device, one can use module.to(device)\n",
        "    and criterion.to(device) so that all the computations will be done on the GPU.\n",
        "    \"\"\"\n",
        "    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "def save_pickle(obj, path):\n",
        "    with open(path, \"wb\") as f:\n",
        "        pickle.dump(obj, f)\n",
        "\n",
        "\n",
        "def load_pickle(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "\n",
        "def save_model(model, path, epoch, optimizer):\n",
        "    \"\"\"\n",
        "    Utility function for saving checkpoint of a model, so training or evaluation can be executed later on.\n",
        "    :param model: torch module representing the model\n",
        "    :param optimizer: torch optimizer used for training the module\n",
        "    :param path: path to save the checkpoint into\n",
        "    \"\"\"\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()}, path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vH7B6bzZGOn2"
      },
      "outputs": [],
      "source": [
        "class OnlineDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A pytorch dataset which generates model inputs on the fly from sentences of SentimentTreeBank\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sent_data, sent_func, sent_func_kwargs):\n",
        "        \"\"\"\n",
        "        :param sent_data: list of sentences from SentimentTreeBank\n",
        "        :param sent_func: Function which converts a sentence to an input datapoint\n",
        "        :param sent_func_kwargs: fixed keyword arguments for the state_func\n",
        "        \"\"\"\n",
        "        self.data = sent_data\n",
        "        self.sent_func = sent_func\n",
        "        self.sent_func_kwargs = sent_func_kwargs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sent = self.data[idx]\n",
        "        sent_emb = self.sent_func(sent, **self.sent_func_kwargs)\n",
        "        sent_label = sent.sentiment_class\n",
        "        return sent_emb, sent_label\n",
        "class DataManager():\n",
        "    \"\"\"\n",
        "    Utility class for handling all data management task. Can be used to get iterators for training and\n",
        "    evaluation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_type=ONEHOT_AVERAGE,\n",
        "                 use_sub_phrases=True,\n",
        "                 dataset_path=\"stanfordSentimentTreebank\",\n",
        "                 batch_size=64,\n",
        "                 embedding_dim=300):\n",
        "        \"\"\"\n",
        "        builds the data manager used for training and evaluation.\n",
        "        :param data_type: one of ONEHOT_AVERAGE, W2V_AVERAGE and W2V_SEQUENCE\n",
        "        :param use_sub_phrases: if true, training data will include all sub-phrases plus the full sentences\n",
        "        :param dataset_path: path to the dataset directory\n",
        "        :param batch_size: number of examples per batch\n",
        "        :param embedding_dim: relevant only for the W2V data types.\n",
        "        \"\"\"\n",
        "\n",
        "        # load the dataset\n",
        "        self.sentiment_dataset = SentimentTreeBank(dataset_path, split_words=True)\n",
        "        # map data splits to sentences lists\n",
        "        self.sentences = {} #train\n",
        "        if use_sub_phrases:\n",
        "            self.sentences[TRAIN] = self.sentiment_dataset.get_train_set_phrases()\n",
        "        else:\n",
        "            self.sentences[TRAIN] = self.sentiment_dataset.get_train_set()\n",
        "\n",
        "        self.sentences[VAL] = self.sentiment_dataset.get_validation_set()\n",
        "        self.sentences[TEST] = self.sentiment_dataset.get_test_set()\n",
        "\n",
        "        self.sentences[NEGATIVE_POLARITY] = [self.sentences[TEST][index] for index in\n",
        "                                            get_negated_polarity_examples(self.sentences[TEST])]\n",
        "\n",
        "        self.sentences[RARE_WORDS] = [self.sentences[TEST][index] for index in\n",
        "                                             get_rare_words_examples(self.sentences[TEST], self.sentiment_dataset)]\n",
        "\n",
        "        # map data splits to sentence input preperation functions\n",
        "        words_list = list(self.sentiment_dataset.get_word_counts().keys())\n",
        "        if data_type == ONEHOT_AVERAGE:\n",
        "            self.sent_func = average_one_hots\n",
        "            self.sent_func_kwargs = {\"word_to_ind\": get_word_to_ind(words_list)}\n",
        "        elif data_type == W2V_SEQUENCE:\n",
        "            self.sent_func = sentence_to_embedding\n",
        "\n",
        "            self.sent_func_kwargs = {\"seq_len\": SEQ_LEN,\n",
        "                                     \"word_to_vec\": create_or_load_slim_w2v(words_list),\n",
        "                                     \"embedding_dim\": embedding_dim\n",
        "                                     }\n",
        "        elif data_type == W2V_AVERAGE:\n",
        "            self.sent_func = get_w2v_average\n",
        "            words_list = list(self.sentiment_dataset.get_word_counts().keys())\n",
        "            self.sent_func_kwargs = {\"word_to_vec\": create_or_load_slim_w2v(words_list),\n",
        "                                     \"embedding_dim\": embedding_dim\n",
        "                                     }\n",
        "        else:\n",
        "            raise ValueError(\"invalid data_type: {}\".format(data_type))\n",
        "        # map data splits to torch datasets and iterators\n",
        "        self.torch_datasets = {k: OnlineDataset(sentences, self.sent_func, self.sent_func_kwargs) for\n",
        "                               k, sentences in self.sentences.items()}\n",
        "        self.torch_iterators = {k: DataLoader(dataset, batch_size=batch_size, shuffle=k == TRAIN)\n",
        "                                for k, dataset in self.torch_datasets.items()}\n",
        "    def get_torch_iterator(self, data_subset=TRAIN):\n",
        "        \"\"\"\n",
        "        :param data_subset: one of TRAIN VAL and TEST\n",
        "        :return: torch batches iterator for this part of the datset\n",
        "        \"\"\"\n",
        "        return self.torch_iterators[data_subset]\n",
        "\n",
        "    def get_labels(self, data_subset=TRAIN):\n",
        "        \"\"\"\n",
        "        :param data_subset: one of TRAIN VAL and TEST\n",
        "        :return: numpy array with the labels of the requested part of the datset in the same order of the\n",
        "        examples.\n",
        "        \"\"\"\n",
        "        return np.array([sent.sentiment_class for sent in self.sentences[data_subset]])\n",
        "\n",
        "    def get_input_shape(self):\n",
        "        \"\"\"\n",
        "        :return: the shape of a single example from this dataset (only of x, ignoring y the label).\n",
        "        \"\"\"\n",
        "        return self.torch_datasets[TRAIN][0][0].shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KVZn5dRcAaLX"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_word2vec():\n",
        "    \"\"\" Load Word2Vec Vectors\n",
        "        Return:\n",
        "            wv_from_bin: All 3 million embeddings, each lengh 300\n",
        "    \"\"\"\n",
        "    import gensim.downloader as api\n",
        "    wv_from_bin = api.load(\"word2vec-google-news-300\")\n",
        "    vocab = list(wv_from_bin.key_to_index.keys())\n",
        "    print(wv_from_bin.key_to_index[vocab[0]])\n",
        "    print(\"Loaded vocab size %i\" % len(vocab))\n",
        "    return wv_from_bin\n",
        "def create_or_load_slim_w2v(words_list, cache_w2v=True):\n",
        "    \"\"\"\n",
        "    returns word2vec dict only for words which appear in the dataset.\n",
        "    :param words_list: list of words to use for the w2v dict\n",
        "    :param cache_w2v: whether to save locally the small w2v dictionary\n",
        "    :return: dictionary which maps the known words to their vectors\n",
        "    \"\"\"\n",
        "    w2v_path = \"w2v_dict.pkl\"\n",
        "    if not os.path.exists(w2v_path):\n",
        "        full_w2v = load_word2vec()\n",
        "        w2v_emb_dict = {k: full_w2v[k] for k in words_list if k in full_w2v}\n",
        "        if cache_w2v:\n",
        "            save_pickle(w2v_emb_dict, w2v_path)\n",
        "    else:\n",
        "        w2v_emb_dict = load_pickle(w2v_path)\n",
        "    return w2v_emb_dict\n",
        "def average_one_hots(sent, word_to_ind):\n",
        "    \"\"\"\n",
        "    This method gets a sentence and a mapping between words to indices, and returns the average\n",
        "    one-hot embedding of the tokens in the sentence.\n",
        "    :param sent: a sentence object.\n",
        "    :param word_to_ind: a mapping between words to indices\n",
        "    :return: The average embedding vector as a numpy ndarray.\n",
        "    \"\"\"\n",
        "    total_word = len(sent.text)\n",
        "    res = np.zeros(len(word_to_ind))\n",
        "    word_count = collections.Counter(sent.text)\n",
        "\n",
        "    for word, count in word_count.items():\n",
        "        if word in word_to_ind:\n",
        "            res[word_to_ind[word]] += count / total_word\n",
        "\n",
        "    return res\n",
        "    # return np.mean([word_to_vec[word] for word in sent.text if word in word_to_vec], axis=0).reshape(-1)\n",
        "\n",
        "    # return\n",
        "def get_one_hot(size, ind) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    this method returns a one-hot vector of the given size, where the 1 is placed in the ind entry.\n",
        "    :param size: the size of the vector\n",
        "    :param ind: the entry index to turn to 1\n",
        "    :return: numpy ndarray which represents the one-hot vector\n",
        "    \"\"\"\n",
        "    # first index is 0\n",
        "    res = np.zeros((size, 1), dtype=np.float32)\n",
        "    res[ind] = 1\n",
        "    return res\n",
        "\n",
        "def get_w2v_average(sent:Sentence, word_to_vec:Dict[str, int], embedding_dim:int=300) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    This method gets a sentence and returns the average word embedding of the words consisting\n",
        "    the sentence.\n",
        "    :param sent: the sentence object\n",
        "    :param word_to_vec: a dictionary mapping words to their vector embeddings\n",
        "    :param embedding_dim: the dimension of the word embedding vectors\n",
        "    :return The average embedding vector as numpy ndarray.\n",
        "    \"\"\"\n",
        "    dict_1 = collections.Counter(sent.text)\n",
        "    res = np.zeros(embedding_dim)\n",
        "    total_word = len(sent.text)\n",
        "    for word, count in dict_1.items():\n",
        "        if word in word_to_vec:\n",
        "            res += (word_to_vec[word] * count) / total_word\n",
        "    return res\n",
        "\n",
        "def get_word_to_ind(words_list:List[str]) -> dict[str, int]:\n",
        "    \"\"\"\n",
        "    this function gets a list of words, and returns a mapping between\n",
        "    words to their index.\n",
        "    :param words_list: a list of words\n",
        "    :return: the dictionary mapping words to the index\n",
        "    \"\"\"\n",
        "    return {word: i for i, word in enumerate(words_list)}\n",
        "\n",
        "def sentence_to_embedding(sent:Sentence, word_to_vec:Dict[str, int], seq_len:int, embedding_dim:int =300):\n",
        "    \"\"\"\n",
        "    this method gets a sentence and a word to vector mapping, and returns a list containing the\n",
        "    words embeddings of the tokens in the sentence.\n",
        "    :param sent: a sentence object\n",
        "    :param word_to_vec: a word to vector mapping.\n",
        "    :param seq_len: the fixed length for which the sentence will be mapped to.\n",
        "    :param embedding_dim: the dimension of the w2v embedding\n",
        "    :return: numpy ndarray of shape (seq_len, embedding_dim) with the representation of the sentence\n",
        "    \"\"\"\n",
        "    # if not embedding_dim:\n",
        "    #     embedding_dim = 300\n",
        "    res = np.zeros((SEQ_LEN, embedding_dim))\n",
        "    text = sent.text\n",
        "    for i, word in enumerate(text):\n",
        "        if i >= seq_len:\n",
        "            break\n",
        "        if word in word_to_vec:\n",
        "            res[i] = word_to_vec[word]\n",
        "    return res\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------- training functions -------------\n",
        "\n",
        "# ------------------------ Print functions ------------------------------------\n",
        "\n",
        "def print_test_results(test_loss, test_accuracy, model_name=\"simple Log-Linear model\"):\n",
        "    \"\"\"\n",
        "    This function prints the results of the testing process.\n",
        "    \"\"\"\n",
        "    print(f'{model_name.title()} {TEST} {LOSS}: {test_loss:.4f}, {TEST} {ACCURACY}: {test_accuracy:.4f}')\n",
        "def plot_training_process(num_epochs: int,\n",
        "                          train_losses: List[float],\n",
        "                          train_accuracies: List[float],\n",
        "                          val_losses: List[float],\n",
        "                          val_accuracies: List[float],\n",
        "                          model_name=\"simple Log-Linear model\",\n",
        "                          save_plots=True):\n",
        "    \"\"\"\n",
        "    This function plots the training process of the model.\n",
        "    \"\"\"\n",
        "\n",
        "    train_and_validation = f\"{TRAIN} & {VALIDATION}\"\n",
        "    def _save_or_show(plt, save_plots:bool, model_name:str, type=LOSS):\n",
        "        if save_plots:\n",
        "            plt.savefig(f\"{model_name}_{type}.png\")\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "    # Plotting the epoch loss\n",
        "    plt.plot(range(1, num_epochs + 1), train_losses, label=f'{TRAIN.title()} Loss')\n",
        "    plt.plot(range(1, num_epochs + 1), val_losses, label=f'{VALIDATION.title()} Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(f'{LOSS.title()}')\n",
        "    plt.title(f\"{model_name.title()} {train_and_validation.title()} Losses\")\n",
        "    plt.legend()\n",
        "    _save_or_show(plt, save_plots, model_name)\n",
        "\n",
        "    # Plotting the Accuracies\n",
        "    plt.plot(range(1, num_epochs + 1), train_accuracies,\n",
        "             label=f'{TRAIN.title()} {ACCURACY.title()}')\n",
        "    plt.plot(range(1, num_epochs + 1), val_accuracies,\n",
        "             label=f'{VALIDATION.title()} {ACCURACY.title()}')\n",
        "    plt.xlabel('Epochs'.title())\n",
        "    plt.ylabel(f'{ACCURACY.title()}')\n",
        "    plt.title(f\"{model_name.title()} {train_and_validation.title()} Accuracies\")\n",
        "    plt.legend()\n",
        "\n",
        "    _save_or_show(plt, save_plots, model_name, ACCURACY)\n",
        "def print_train_results(epoch,\n",
        "                        num_epochs,\n",
        "                        epoch_train_loss,\n",
        "                        epoch_train_accuracy,\n",
        "                        epoch_val_loss,\n",
        "                        epoch_val_accuracy, model_name=\"simple Log-Linear model\"):\n",
        "    \"\"\"\n",
        "    This function prints the results of the training process.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f'{model_name.title()} Epoch {epoch + 1}/{num_epochs}, '\n",
        "          f'{model_name.title()} {TRAIN.title()} {LOSS.title()}: {epoch_train_loss:.4f}, {TRAIN.title()} {ACCURACY.title()}: {epoch_train_accuracy:.4f}, '\n",
        "          f'{model_name.title()} {VALIDATION.title()} {LOSS.title()}: {epoch_val_loss:.4f}, {VALIDATION.title()} {ACCURACY.title()}: {epoch_val_accuracy:.4f}\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJNTmm2GenSl"
      },
      "source": [
        "### Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Rbqjwciacg1D"
      },
      "outputs": [],
      "source": [
        "def train_transformer_with_distilroberta():\n",
        "    \"\"\"\n",
        "    Trains and evaluates a Transformer model (DistilRoBERTa) for the sentiment analysis task.\n",
        "    \"\"\"\n",
        "    # Load the dataset using DataManager\n",
        "    data_manager = DataManager(W2V_SEQUENCE, embedding_dim=300, batch_size=64)\n",
        "\n",
        "    # Load the tokenizer and model\n",
        "    tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base')\n",
        "    model = DistilBertForSequenceClassification.from_pretrained('distilroberta-base', num_labels=1).to(get_available_device())\n",
        "\n",
        "    # Prepare DataLoader for Transformer\n",
        "    train_sentences = data_manager.sentences[TRAIN]\n",
        "    val_sentences = data_manager.sentences[VAL]\n",
        "    test_sentences = data_manager.sentences[TEST]\n",
        "\n",
        "    def encode_sentences(sentences, tokenizer, max_length=52):\n",
        "        \"\"\"Helper function to tokenize sentences.\"\"\"\n",
        "        texts = [\" \".join(sent.text) for sent in sentences]\n",
        "        labels = [sent.sentiment_class for sent in sentences]\n",
        "        encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='pt')\n",
        "        return TensorDataset(encodings['input_ids'], encodings['attention_mask'], torch.tensor(labels))\n",
        "\n",
        "    train_data = encode_sentences(train_sentences, tokenizer)\n",
        "    val_data = encode_sentences(val_sentences, tokenizer)\n",
        "    test_data = encode_sentences(test_sentences, tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=64)\n",
        "    test_loader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "    # Optimizer and Scheduler\n",
        "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "    scheduler = get_scheduler(\"linear\", optimizer, num_warmup_steps=0, num_training_steps=2 * len(train_loader))\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss().to(get_available_device())\n",
        "\n",
        "    # Training Loop\n",
        "    train_loss, train_acc = [], []\n",
        "    val_loss, val_acc = [], []\n",
        "\n",
        "    for epoch in range(2):  # 2 epochs as specified\n",
        "        model.train()\n",
        "        epoch_loss, epoch_acc = 0, 0\n",
        "        for batch in train_loader:\n",
        "            input_ids, attention_mask, labels = [x.to(get_available_device()) for x in batch]\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += binary_accuracy(logits, labels).cpu().item()  # Move tensor to CPU\n",
        "\n",
        "        train_loss.append(epoch_loss / len(train_loader))\n",
        "        train_acc.append(epoch_acc / len(train_loader))\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_epoch_loss, val_epoch_acc = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                input_ids, attention_mask, labels = [x.to(get_available_device()) for x in batch]\n",
        "\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "                logits = outputs.logits\n",
        "\n",
        "                val_epoch_loss += loss.item()\n",
        "                val_epoch_acc += binary_accuracy(logits, labels).cpu().item()  # Move tensor to CPU\n",
        "\n",
        "        val_loss.append(val_epoch_loss / len(val_loader))\n",
        "        val_acc.append(val_epoch_acc / len(val_loader))\n",
        "\n",
        "        print_train_results(epoch, 2, train_loss[-1], train_acc[-1], val_loss[-1], val_acc[-1], model_name=\"Transformer\")\n",
        "\n",
        "    # Plot results\n",
        "    plot_training_process(2, train_loss, train_acc, val_loss, val_acc, model_name=\"Transformer\")\n",
        "\n",
        "    # Test Set Evaluation\n",
        "    model.eval()\n",
        "    test_epoch_loss, test_epoch_acc = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids, attention_mask, labels = [x.to(get_available_device()) for x in batch]\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            test_epoch_loss += loss.item()\n",
        "            test_epoch_acc += binary_accuracy(logits, labels).cpu().item()  # Move tensor to CPU\n",
        "\n",
        "    print_test_results(test_epoch_loss / len(test_loader), test_epoch_acc / len(test_loader), \"Transformer\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer v2.0"
      ],
      "metadata": {
        "id": "zgNPDsIho2U3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### helpers"
      ],
      "metadata": {
        "id": "ea44rzgK8mKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(data_iter, tokenizer, batch_size, max_len):\n",
        "    dataset = []\n",
        "    for inputs, labels in data_iter:\n",
        "        # Ensure inputs are strings\n",
        "        if not isinstance(inputs[0], str):\n",
        "            inputs = [str(input_) for input_ in inputs]\n",
        "\n",
        "        # Tokenize inputs\n",
        "        encodings = tokenizer(inputs, truncation=True, padding=True, max_length=max_len, return_tensors=\"pt\")\n",
        "\n",
        "        # Combine tokenized inputs and labels into a dictionary\n",
        "        for i in range(len(inputs)):\n",
        "            dataset.append({\n",
        "                \"input_ids\": encodings[\"input_ids\"][i],\n",
        "                \"attention_mask\": encodings[\"attention_mask\"][i],\n",
        "                \"labels\": torch.tensor(labels[i], dtype=torch.long)\n",
        "            })\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "BH-0lEF88fW_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset for tokenized data and labels.\n",
        "    \"\"\"\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "        # Ensure encodings and labels are aligned\n",
        "        if len(self.labels) != len(self.encodings['input_ids']):\n",
        "            raise ValueError(\n",
        "                f\"Mismatch between encodings and labels: {len(self.encodings['input_ids'])} vs {len(self.labels)}\"\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Ensure valid indexing\n",
        "        if idx >= len(self.labels):\n",
        "            raise IndexError(f\"Index {idx} out of bounds for dataset of size {len(self.labels)}\")\n",
        "\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "A37bGA0G99e2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "FBJMm_TfelCM"
      },
      "outputs": [],
      "source": [
        "def train_transformer_with_distilroberta_v2(data_manager, n_epochs=2, lr=5e-6, weight_decay=0.0, batch_size=16, max_len=52):\n",
        "    \"\"\"\n",
        "    Train and evaluate a Transformer model (distilroberta-base) for sentiment classification.\n",
        "\n",
        "    :param data_manager: DataManager object handling dataset and iterators.\n",
        "    :param n_epochs: Number of epochs for training.\n",
        "    :param lr: Learning rate for the optimizer.\n",
        "    :param weight_decay: Weight decay for L2 regularization.\n",
        "    :param batch_size: Batch size for DataLoader.\n",
        "    :param max_len: Maximum sequence length for tokenization.\n",
        "    \"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "    # Load model and tokenizer\n",
        "    tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base')\n",
        "    model = RobertaForSequenceClassification.from_pretrained('distilroberta-base', num_labels=1).to(device)\n",
        "\n",
        "    # Define optimizer and loss function\n",
        "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "    # Prepare datasets\n",
        "    train_loader = prepare_dataset(data_manager.get_torch_iterator(TRAIN), tokenizer, batch_size, max_len)\n",
        "    val_loader = prepare_dataset(data_manager.get_torch_iterator(VAL), tokenizer, batch_size, max_len)\n",
        "\n",
        "    # Training and validation\n",
        "    train_losses, val_losses, val_accuracies = [], [], []\n",
        "    best_val_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
        "\n",
        "        # Training\n",
        "        train_loss = train_epoch_transformer_with_distilroberta_v2(model, train_loader, optimizer, criterion, device)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Validation\n",
        "        val_loss, val_accuracy = evaluate_model(model, val_loader, criterion, device)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Save the best model\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            torch.save(model.state_dict(), f\"best_model_epoch_{epoch + 1}.pt\")\n",
        "\n",
        "    # Evaluate on special cases\n",
        "    evaluate_special_cases(model, data_manager, tokenizer, device, max_len)\n",
        "\n",
        "    # Plot training progress\n",
        "    plot_training_process(n_epochs, train_losses, val_losses, val_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_epoch_transformer_with_distilroberta_v2(model, data_loader, optimizer, criterion, device):\n",
        "    \"\"\"\n",
        "    Perform an epoch of training for the model.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch in tqdm(data_loader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits.squeeze()\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FRhC5d3G-BS0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on validation or test data.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss, total_accuracy = 0.0, 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device).squeeze(-1)  # Ensure labels have correct shape [batch_size]\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits.squeeze()\n",
        "            loss = criterion(logits, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            predictions = torch.round(torch.sigmoid(logits))\n",
        "            total_accuracy += (predictions == labels).float().mean().item()\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    avg_accuracy = total_accuracy / len(data_loader)\n",
        "    return avg_loss, avg_accuracy"
      ],
      "metadata": {
        "id": "iTxGX4z28uEs"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_special_cases(model, data_manager, tokenizer, device, max_len):\n",
        "    \"\"\"\n",
        "    Evaluate model on special subsets (NEGATIVE_POLARITY and RARE_WORDS).\n",
        "    \"\"\"\n",
        "    print(\"________________________________________________________________________________________________\")\n",
        "    print(\"NEGS: \")\n",
        "    neg_loader = prepare_dataset(data_manager.get_torch_iterator(NEGATIVE_POLARITY), tokenizer, 16, max_len)\n",
        "    predictions_neg, labels_neg = get_predictions_for_transformer(model, neg_loader, device)\n",
        "    neg_accuracy = binary_accuracy(predictions_neg, labels_neg)\n",
        "    neg_loss = nn.BCEWithLogitsLoss()(predictions_neg.squeeze(), labels_neg)\n",
        "    print_test_results(neg_loss, neg_accuracy, \"NEGATIVE_POLARITY\")\n",
        "\n",
        "    print(\"________________________________________________________________________________________________\")\n",
        "    print(\"RARE: \")\n",
        "    rare_loader = prepare_dataset(data_manager.get_torch_iterator(RARE_WORDS), tokenizer, 16, max_len)\n",
        "    predictions_rare, labels_rare = get_predictions_for_transformer(model, rare_loader, device)\n",
        "    rare_accuracy = binary_accuracy(predictions_rare, labels_rare)\n",
        "    rare_loss = nn.BCEWithLogitsLoss()(predictions_rare.squeeze(), labels_rare)\n",
        "    print_test_results(rare_loss, rare_accuracy, \"RARE_WORDS\")\n",
        "\n",
        "def get_predictions_for_transformer(model, data_loader, device):\n",
        "    \"\"\"\n",
        "    Get predictions for a given dataset.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions, labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            batch_labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits.squeeze()\n",
        "            predictions.append(logits)\n",
        "            labels.append(batch_labels)"
      ],
      "metadata": {
        "id": "N_bsEpfZ8qgl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlYG80Lcfwws"
      },
      "source": [
        "### Other models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "F5iqJVtzGmdF"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    This method returns the accuracy of the predictions, relative to the labels.\n",
        "    :param preds: a tensor of predictions\n",
        "    :param y: a tensor of true labels\n",
        "    :return: scalar value - (<number of accurate predictions> / <number of examples>)\n",
        "    \"\"\"\n",
        "    # Apply sigmoid to predictions\n",
        "    preds = torch.sigmoid(preds)\n",
        "\n",
        "    # Round predictions to 0/1\n",
        "    pred_labels = torch.round(preds)\n",
        "\n",
        "    # Cast to float, ensure same datatype\n",
        "    y = y.float()\n",
        "\n",
        "    # Move y to the same device as pred_labels\n",
        "    y = y.to(pred_labels.device)\n",
        "\n",
        "    # Compute number of accurate predictions\n",
        "    correct = (pred_labels == y).float().sum()\n",
        "\n",
        "    # Divide by number of examples for accuracy\n",
        "    acc = correct / len(y)\n",
        "\n",
        "    return acc\n",
        "\n",
        "    # preds = torch.sigmoid(preds)\n",
        "    # # Convert predictions to binary values (0 or 1)\n",
        "    # preds_binary = (preds >= 0.5).float()\n",
        "    #\n",
        "    # # Count the number of accurate predictions\n",
        "    # correct_predictions = (preds_binary == y).sum().item()\n",
        "    #\n",
        "    # # Calculate accuracy\n",
        "    # accuracy = correct_predictions / len(y)\n",
        "    #\n",
        "    # return accuracy\n",
        "def train_epoch(model, data_iterator, optimizer, criterion) -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    This method operates one epoch (pass over the whole train set) of training\n",
        "    of the given model,\n",
        "    and returns the accuracy and loss for this epoch\n",
        "    :param model: the model we're currently training\n",
        "    :param data_iterator: an iterator, iterating over the training data for the model.\n",
        "    :param optimizer: the optimizer object for the training process.\n",
        "    :param criterion: the criterion object for the training process.\n",
        "    \"\"\"\n",
        "    # batch_counter = 0\n",
        "    # epoch_loss = 0\n",
        "    # epoch_accuracy = 0\n",
        "\n",
        "    model.train()  # set the model to training mode\n",
        "    for train_features, train_labels in data_iterator:\n",
        "        train_features = train_features.to(get_available_device())\n",
        "        train_labels = train_labels.to(get_available_device())\n",
        "        #start_time = time.time()\n",
        "        outputs = model(train_features).to(get_available_device())\n",
        "        optimizer.zero_grad()\n",
        "        # train_features = train_features.squeeze(-1)\n",
        "        # outputs = model(train_features).squeeze(-1)\n",
        "        train_labels = train_labels.unsqueeze(-1)\n",
        "        loss = criterion(outputs, train_labels).to(get_available_device())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    model.train(False)\n",
        "\n",
        "        # epoch_loss += loss.item()  # assuming loss is a scalar tensor\n",
        "        # epoch_accuracy += binary_accuracy(torch.sigmoid(outputs), train_labels)\n",
        "        #\n",
        "        # batch_counter += 1\n",
        "        # print(\"BATCH \" + str(batch_counter) + \" ENDED. loss, accuracy:\", epoch_loss, epoch_accuracy, time.time() - start_time)\n",
        "\n",
        "    # average_loss = epoch_loss / len(data_iterator)\n",
        "    # average_accuracy = epoch_accuracy / len(data_iterator)\n",
        "    #\n",
        "    # return average_loss, average_accuracy\n",
        "\n",
        "\n",
        "def get_predictions_for_data(model, data_iter):\n",
        "    \"\"\"\n",
        "    This function should iterate over all batches of examples from data_iter and return all of the models\n",
        "    predictions as a numpy ndarray or torch tensor (or list if you prefer). the prediction should be in the\n",
        "    same order of the examples returned by data_iter.\n",
        "    :param model: one of the models you implemented in the exercise\n",
        "    :param data_iter: torch iterator as given by the DataManager\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    res = []\n",
        "    for i, batch in enumerate(data_iter):\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(model.device) # move input to the model's device\n",
        "        outputs = model.predict(inputs)\n",
        "        if i == 0:\n",
        "            res = outputs\n",
        "        else:\n",
        "            res = torch.cat((res, outputs), dim=0)\n",
        "    return res\n",
        "\n",
        "def train_model(model, data_manager, n_epochs=20, lr=0.01, weight_decay=0., model_name=\"Simple Log-Linear\") -> None:\n",
        "    \"\"\"\n",
        "    Runs the full training procedure for the given model. The optimization should be done using the Adam\n",
        "    optimizer with all parameters but learning rate and weight decay set to default.\n",
        "    :param model: module of one of the models implemented in the exercise\n",
        "    :param data_manager: the DataManager object\n",
        "    :param n_epochs: number of times to go over the whole training set\n",
        "    :param lr: learning rate to be used for optimization\n",
        "    :param weight_decay: parameter for l2 regularization\n",
        "    \"\"\"\n",
        "    train_loss = []\n",
        "    train_accuracy = []\n",
        "    validation_loss = []\n",
        "    validation_accuracy = []\n",
        "    model_parameters:Iterable[Tensor] = model.parameters()\n",
        "    optimizer = optim.Adam(model_parameters, lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.BCEWithLogitsLoss().to(get_available_device())\n",
        "    data_iterator = data_manager.get_torch_iterator(TRAIN)\n",
        "    for epoch in range(n_epochs):\n",
        "        # train the model for one epoch\n",
        "        # evaluate the model on the validation set\n",
        "        # print the results for the epoch\n",
        "        # save the model if it got the best validation accuracy until now\n",
        "        # cur_train_loss, cur_train_accuracy = train_epoch(model=model,\n",
        "        #                                                 data_iterator=data_manager.get_torch_iterator(data_subset=TRAIN),\n",
        "        #                                                 optimizer=optimizer,\n",
        "        #                                                 criterion=criterion)\n",
        "        train_epoch(model=model,\n",
        "                    data_iterator=data_iterator,\n",
        "                    optimizer=optimizer,\n",
        "                    criterion=criterion.to(get_available_device()))\n",
        "        cur_train_loss, cur_train_accuracy = evaluate(model=model, data_iterator=data_iterator, criterion=criterion)\n",
        "        train_loss.append(cur_train_loss)\n",
        "        train_accuracy.append(cur_train_accuracy)\n",
        "        cur_val_loss, cur_val_accuracy = evaluate(model,\n",
        "                                                  data_manager.get_torch_iterator(VAL),\n",
        "                                                  criterion.to(get_available_device()))\n",
        "\n",
        "        validation_loss.append(cur_val_loss)\n",
        "        validation_accuracy.append(cur_val_accuracy)\n",
        "        print_train_results(epoch, n_epochs, cur_train_loss, cur_train_accuracy, cur_val_loss, cur_val_accuracy, model_name=model_name)\n",
        "    plot_training_process(n_epochs, train_loss, train_accuracy, validation_loss, validation_accuracy, model_name)\n",
        "def train_log_linear_with_one_hot():\n",
        "    \"\"\"\n",
        "    Here comes your code for training and evaluation of the log linear model with one hot representation.\n",
        "    \"\"\"\n",
        "    data_manager = DataManager()#batch_size=64)\n",
        "                                # data_type=ONEHOT_AVERAGE)\n",
        "                                # use_sub_phrases=True,\n",
        "                                # dataset_path=\"stanfordSentimentTreebank\",\n",
        "                                # batch_size=50,\n",
        "                                # embedding_dim=None)\n",
        "    one_hot_size = data_manager.get_input_shape()[0]\n",
        "    linear_model = LogLinear(one_hot_size).to(get_available_device())\n",
        "    train_model(model=linear_model,\n",
        "                data_manager=data_manager,\n",
        "                n_epochs=20, weight_decay=0.001, lr=0.01)\n",
        "    predictions = get_predictions_for_data(linear_model, data_manager.get_torch_iterator(TEST))\n",
        "    lables = data_manager.get_labels(TEST)\n",
        "    test_accuracy = binary_accuracy(predictions.squeeze().round(), torch.tensor(lables))\n",
        "    test_loss = nn.BCEWithLogitsLoss()(predictions.squeeze(), torch.tensor(lables))\n",
        "    print_test_results(test_loss, test_accuracy)\n",
        "\n",
        "    print(\"________________________________________________________________________________________________\")\n",
        "    print(\"NEGS: \")\n",
        "\n",
        "    predictions_neg = get_predictions_for_data(linear_model, data_manager.get_torch_iterator(NEGATIVE_POLARITY))\n",
        "    lables_neg = data_manager.get_labels(NEGATIVE_POLARITY)\n",
        "    test_accuracy_neg = binary_accuracy(predictions_neg.squeeze().round(), torch.tensor(lables_neg))\n",
        "    test_loss_neg = nn.BCEWithLogitsLoss()(predictions_neg.squeeze(), torch.tensor(lables_neg))\n",
        "    print_test_results(test_loss_neg, test_accuracy_neg)\n",
        "\n",
        "    print(\"________________________________________________________________________________________________\")\n",
        "    print(\"RARE: \")\n",
        "\n",
        "    predictions_rare = get_predictions_for_data(linear_model, data_manager.get_torch_iterator(RARE_WORDS))\n",
        "    lables_rare = data_manager.get_labels(RARE_WORDS)\n",
        "    test_accuracy_rare = binary_accuracy(predictions_rare.squeeze().round(), torch.tensor(lables_rare))\n",
        "    test_loss_rare = nn.BCEWithLogitsLoss()(predictions_rare.squeeze(), torch.tensor(lables_rare))\n",
        "    print_test_results(test_loss_rare, test_accuracy_rare)\n",
        "\n",
        "def train_log_linear_with_w2v():\n",
        "    \"\"\"\n",
        "    Here comes your code for training and evaluation of the log linear model with word embeddings\n",
        "    representation.\n",
        "    \"\"\"\n",
        "    data_manager = DataManager(data_type=W2V_AVERAGE,\n",
        "                               embedding_dim=300,\n",
        "                               batch_size=64)\n",
        "    linear_model = LogLinear(300).to(get_available_device())\n",
        "    train_model(model=linear_model,\n",
        "                data_manager=data_manager,\n",
        "                n_epochs=20,\n",
        "                model_name=\"log linear with W2V\", weight_decay=0.001, lr=0.01)\n",
        "    predictions = get_predictions_for_data(linear_model,\n",
        "                                           data_manager.get_torch_iterator(\n",
        "                                               TEST))\n",
        "    lables = data_manager.get_labels(TEST)\n",
        "    lables = torch.tensor(lables, device=predictions.device)\n",
        "\n",
        "    test_accuracy = binary_accuracy(predictions.squeeze().round(),\n",
        "                                    torch.tensor(lables))\n",
        "    test_loss = nn.BCEWithLogitsLoss()(predictions.squeeze(),\n",
        "                                       torch.tensor(lables))\n",
        "    print_test_results(test_loss, test_accuracy, \"log linear with W2V\")\n",
        "\n",
        "    print(\"________________________________________________________________________________________________\")\n",
        "    print(\"NEGS: \")\n",
        "\n",
        "    predictions_neg = get_predictions_for_data(linear_model, data_manager.get_torch_iterator(NEGATIVE_POLARITY))\n",
        "    lables_neg = data_manager.get_labels(NEGATIVE_POLARITY)\n",
        "    test_accuracy_neg = binary_accuracy(predictions_neg.squeeze().round(), torch.tensor(lables_neg))\n",
        "    test_loss_neg = nn.BCEWithLogitsLoss()(predictions_neg.squeeze(), torch.tensor(lables_neg))\n",
        "    print_test_results(test_loss_neg, test_accuracy_neg)\n",
        "\n",
        "    print(\"________________________________________________________________________________________________\")\n",
        "    print(\"RARE: \")\n",
        "\n",
        "    predictions_rare = get_predictions_for_data(linear_model, data_manager.get_torch_iterator(RARE_WORDS))\n",
        "    lables_rare = data_manager.get_labels(RARE_WORDS)\n",
        "    test_accuracy_rare = binary_accuracy(predictions_rare.squeeze().round(), torch.tensor(lables_rare))\n",
        "    test_loss_rare = nn.BCEWithLogitsLoss()(predictions_rare.squeeze(), torch.tensor(lables_rare))\n",
        "    print_test_results(test_loss_rare, test_accuracy_rare)\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def train_lstm_with_w2v():\n",
        "    \"\"\"\n",
        "    Here comes your code for training and evaluation of the LSTM model.\n",
        "    \"\"\"\n",
        "    data_manager = DataManager(W2V_SEQUENCE, embedding_dim=300, batch_size=64)\n",
        "    lstm_model = LSTM(embedding_dim=300, hidden_dim=100, n_layers=1, dropout=0.5).to(get_available_device())\n",
        "\n",
        "    train_model(model=lstm_model, data_manager=data_manager, n_epochs=4, model_name=\"LSTM model with W2V\", lr=0.001, weight_decay=0.0001)\n",
        "    predictions = get_predictions_for_data(lstm_model,\n",
        "                                           data_manager.get_torch_iterator(\n",
        "                                               TEST))\n",
        "    lables = data_manager.get_labels(TEST)\n",
        "    test_accuracy = binary_accuracy(predictions.squeeze().round(),\n",
        "                                    torch.tensor(lables))\n",
        "    test_loss = nn.BCEWithLogitsLoss()(predictions.squeeze(),\n",
        "                                       torch.tensor(lables))\n",
        "    print_test_results(test_loss, test_accuracy, \"LSTM model with W2V\")\n",
        "\n",
        "    print(\"________________________________________________________________________________________________\")\n",
        "    print(\"NEGS: \")\n",
        "\n",
        "    predictions_neg = get_predictions_for_data(lstm_model, data_manager.get_torch_iterator(NEGATIVE_POLARITY))\n",
        "    lables_neg = data_manager.get_labels(NEGATIVE_POLARITY)\n",
        "    test_accuracy_neg = binary_accuracy(predictions_neg.squeeze().round(), torch.tensor(lables_neg))\n",
        "    test_loss_neg = nn.BCEWithLogitsLoss()(predictions_neg.squeeze(), torch.tensor(lables_neg))\n",
        "    print_test_results(test_loss_neg, test_accuracy_neg)\n",
        "\n",
        "    print(\"________________________________________________________________________________________________\")\n",
        "    print(\"RARE: \")\n",
        "\n",
        "    predictions_rare = get_predictions_for_data(lstm_model, data_manager.get_torch_iterator(RARE_WORDS))\n",
        "    lables_rare = data_manager.get_labels(RARE_WORDS)\n",
        "    test_accuracy_rare = binary_accuracy(predictions_rare.squeeze().round(), torch.tensor(lables_rare))\n",
        "    test_loss_rare = nn.BCEWithLogitsLoss()(predictions_rare.squeeze(), torch.tensor(lables_rare))\n",
        "    print_test_results(test_loss_rare, test_accuracy_rare)\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqNkwmlfX2n"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Y4SJdshDX1vi"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_iterator, criterion):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the validation set.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_iterator:\n",
        "            validation_features, validation_labels = batch\n",
        "            # validation_features = validation_features.squeeze(-1)\n",
        "\n",
        "            # Move validation_features and validation_labels to the correct device\n",
        "            validation_features = validation_features.to(get_available_device())\n",
        "            validation_labels = validation_labels.to(get_available_device()) # Move labels to device\n",
        "\n",
        "            outputs = model(validation_features)\n",
        "            validation_labels = validation_labels.unsqueeze(-1)\n",
        "            loss = criterion(outputs, validation_labels) # Remove .to() here\n",
        "\n",
        "            total_loss += loss.item() * validation_features.size(0)\n",
        "            predicted = (outputs > 0.5).int()\n",
        "            total_correct += (predicted == validation_labels).sum().item()\n",
        "            total_samples += validation_features.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = total_correct / total_samples\n",
        "\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTY3jPaXf1Yv"
      },
      "source": [
        "## Main run"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init_data_manager = False"
      ],
      "metadata": {
        "id": "uUIpbCWJ_mwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "zoHnKpHGXcRB",
        "outputId": "20a30bb0-cc03-4df0-a586-54d1bee5cdc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init_data_manager=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not str",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-527ba4be2d88>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mdata_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2V_SEQUENCE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0minit_data_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_transformer_with_distilroberta_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-878425a47ba2>\u001b[0m in \u001b[0;36mtrain_transformer_with_distilroberta_v2\u001b[0;34m(data_manager, n_epochs, lr, weight_decay, batch_size, max_len)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch_transformer_with_distilroberta_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-a69c6c5f229f>\u001b[0m in \u001b[0;36mtrain_epoch_transformer_with_distilroberta_v2\u001b[0;34m(model, data_loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    # train_log_linear_with_one_hot()\n",
        "    #train_log_linear_with_w2v()\n",
        "    # train_lstm_with_w2v()\n",
        "    # train_transformer_with_distilroberta()\n",
        "    # data_manager = DataManager(W2V_SEQUENCE, embedding_dim=300, batch_size=64)\n",
        "    print(f\"{init_data_manager=}\")\n",
        "    if init_data_manager:\n",
        "      device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "      data_manager = DataManager(W2V_SEQUENCE, embedding_dim=300, batch_size=64)\n",
        "      init_data_manager = False\n",
        "    train_transformer_with_distilroberta_v2(data_manager)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Debugging"
      ],
      "metadata": {
        "id": "1YFiHPk--6iQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = data_manager.get_torch_iterator(TRAIN)\n",
        "\n",
        "for i, (inputs, labels) in enumerate(data_iter):\n",
        "    print(f\"Batch {i}: Inputs: {len(inputs)}, Labels: {len(labels)}\")\n",
        "    if len(inputs) != len(labels):\n",
        "        raise ValueError(f\"Mismatch in batch {i}: {len(inputs)} inputs vs {len(labels)} labels\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NMjr-Zk9-tPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = data_manager.get_torch_iterator(TRAIN)\n",
        "\n",
        "# Count the total number of inputs and labels\n",
        "total_inputs = 0\n",
        "total_labels = 0\n",
        "\n",
        "for inputs, labels in data_iter:\n",
        "    total_inputs += len(inputs)\n",
        "    total_labels += len(labels)\n",
        "\n",
        "print(f\"Total inputs: {total_inputs}, Total labels: {total_labels}\")"
      ],
      "metadata": {
        "id": "AsNGpriX-kpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = data_manager.get_torch_iterator(TRAIN)\n",
        "\n",
        "# Debugging the iterator\n",
        "for i, (input_text, label) in enumerate(data_iter):\n",
        "    print(f\"Input {i}: {input_text}, Label: {label}\")\n",
        "    if i == 10:  # Check the first 10 samples\n",
        "        break"
      ],
      "metadata": {
        "id": "Xl69NBmk-ZVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_data_manager = True"
      ],
      "metadata": {
        "id": "oEVSQkMF66w4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1oxEny__-UPOYa7tnzCM7LqFxIx7WQSQC",
      "authorship_tag": "ABX9TyM3DX2GF53KPIl/yeV+ezWK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0312dfaa41b64686ae60fb1572689f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a2915187f5d4b2f8362b7c0a74c71a8",
              "IPY_MODEL_f9bc15b7a7874e3487f1f92d36cd0d34",
              "IPY_MODEL_a1182e579646422eaa2f86f9ba291ad6"
            ],
            "layout": "IPY_MODEL_8ce902a31d7244b5a7eefc57dd6a02e4"
          }
        },
        "039408981637400fa52fda71be866d5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0564a3cf2e9c480a9e26b23051809353": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08a66672afa74e41b218c1b5fccf93da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b438b184fc343ccb9d056714ea78b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_171f4fad126d4ae6a337266322df23a1",
            "max": 331055963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36c535998b924beab1ec18effd91a74a",
            "value": 331055963
          }
        },
        "0fef14c7a5fb4d36a9c68f786da279b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64d9b55d9f5743ebb4052f7b55cc4ec0",
              "IPY_MODEL_6f2f4c5c98fd41b4a4d20a8549fea225",
              "IPY_MODEL_d03df5cc5edb49b795c8c3597d3809e7"
            ],
            "layout": "IPY_MODEL_47c0eb1966084aab8ad328dc6661545c"
          }
        },
        "13c271479baf44faba08b5c17b92141b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ae6a7a2a68b4e4d925469d64de33aa0",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbe7bf5f35a64273a3fcd4d270b2a038",
            "value": 25
          }
        },
        "171f4fad126d4ae6a337266322df23a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1793d0fd51154ef5b24af7a7bcd789a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "194eda19f5c44bd5b9e06036929befd0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ae6a7a2a68b4e4d925469d64de33aa0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cbb23ad46e2468aaef2a7b247bf21ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff9178ea9c464c38aa0729083c3fd257",
              "IPY_MODEL_0b438b184fc343ccb9d056714ea78b17",
              "IPY_MODEL_6e8c550401b34ebc9f4abda27b087e66"
            ],
            "layout": "IPY_MODEL_194eda19f5c44bd5b9e06036929befd0"
          }
        },
        "1cf145481c7f4a9abfbc90f787cdf49a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22b6083bff8c4c20949750f48e83a575": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22f8f2326125403098e8f4be917edb72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "254e0410a4c44f7eb867457623052a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fdc012519f14375b2bf3cde5063d428": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36c535998b924beab1ec18effd91a74a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a7e73e365bc4f51914ef9807d2bd2e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aaa830ebfd34e3296b554713032da5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b2a2c7cecd243e19af31556fbf43d46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dfae937d51942d48ce4baefb905461b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dc99a7da0c84286bf30216e7fca2db3",
              "IPY_MODEL_8ee41997f7204d9f89be2326170d7620",
              "IPY_MODEL_f85fc5140a0c45ff8ad4553aeded38bc"
            ],
            "layout": "IPY_MODEL_509a09eec5d74cc7a909a80e734a8da8"
          }
        },
        "4297cf09052f458796c7c95c89c6f762": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45d9676fc9d84d4d8b3be8e61f26963d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47c0eb1966084aab8ad328dc6661545c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4839692b8f944b569cf79e1a908c61c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "509a09eec5d74cc7a909a80e734a8da8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52339bf0d7b746639843cbc62f2dfa30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adec4c09e7e24154af5e12225ba64f8d",
              "IPY_MODEL_13c271479baf44faba08b5c17b92141b",
              "IPY_MODEL_ba2915bcbb014d98af038d8b98a13fa8"
            ],
            "layout": "IPY_MODEL_5d96e16a4c3b497ba1feee8e08d8736f"
          }
        },
        "55bf832e97b147ae9bb036e07b2f59c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b70e3072faa4e919b70ae4be36a301b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c55c10cda124c02b0107d32c27ea06b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e57440c57864ae2ba79db8d2ea867be",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_844c4ec6b8fe474eac4ca87da5e4480c",
            "value": 4203
          }
        },
        "5d96e16a4c3b497ba1feee8e08d8736f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e57440c57864ae2ba79db8d2ea867be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e7cdcf6101341538bb0fb43c20b1182": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "640553a9a1754585a2d40c53fae87cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64d9b55d9f5743ebb4052f7b55cc4ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0564a3cf2e9c480a9e26b23051809353",
            "placeholder": "",
            "style": "IPY_MODEL_254e0410a4c44f7eb867457623052a7c",
            "value": "tokenizer.json:100%"
          }
        },
        "65e4906fd5934796863f352e5ae90c33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6df45a7322cc483db8ef616d8c6bd69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e8c550401b34ebc9f4abda27b087e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fbb21e09bf943899202dafeb56347d8",
            "placeholder": "",
            "style": "IPY_MODEL_45d9676fc9d84d4d8b3be8e61f26963d",
            "value": "331M/331M[00:02&lt;00:00,197MB/s]"
          }
        },
        "6f2f4c5c98fd41b4a4d20a8549fea225": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a7e73e365bc4f51914ef9807d2bd2e1",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22b6083bff8c4c20949750f48e83a575",
            "value": 1355863
          }
        },
        "700e628f92f04d14a9b8497ec0598c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "757b474584c24dbfbc1f14c40c4c2338": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "844c4ec6b8fe474eac4ca87da5e4480c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b2c9293259f4400bfd484117e0e350e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ce902a31d7244b5a7eefc57dd6a02e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dc99a7da0c84286bf30216e7fca2db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1666b0761ee4e329ed6351e44eff1ad",
            "placeholder": "",
            "style": "IPY_MODEL_640553a9a1754585a2d40c53fae87cae",
            "value": "merges.txt:100%"
          }
        },
        "8ee41997f7204d9f89be2326170d7620": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c899dc14c914c3f8d69620d09e2f64c",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3aaa830ebfd34e3296b554713032da5a",
            "value": 456318
          }
        },
        "8fbb21e09bf943899202dafeb56347d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98c211278daf4ef89ac703ffc7a3f537": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e7cdcf6101341538bb0fb43c20b1182",
            "placeholder": "",
            "style": "IPY_MODEL_08a66672afa74e41b218c1b5fccf93da",
            "value": "Downloadingbuilderscript:100%"
          }
        },
        "9a2915187f5d4b2f8362b7c0a74c71a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22f8f2326125403098e8f4be917edb72",
            "placeholder": "",
            "style": "IPY_MODEL_b5cc1d12347c4e8b9d843c6502d6abe6",
            "value": "vocab.json:100%"
          }
        },
        "9c899dc14c914c3f8d69620d09e2f64c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1182e579646422eaa2f86f9ba291ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9f57d7db264440ab0a7c77c098322f0",
            "placeholder": "",
            "style": "IPY_MODEL_d84064d3ec0e40759c78a3750bd8d30f",
            "value": "899k/899k[00:00&lt;00:00,6.24MB/s]"
          }
        },
        "a79c4c66d58d46d39f8c47eca7012de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f239b67772ec476ca31d6369930ce534",
            "placeholder": "",
            "style": "IPY_MODEL_700e628f92f04d14a9b8497ec0598c41",
            "value": "config.json:100%"
          }
        },
        "a9f57d7db264440ab0a7c77c098322f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adec4c09e7e24154af5e12225ba64f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65e4906fd5934796863f352e5ae90c33",
            "placeholder": "",
            "style": "IPY_MODEL_757b474584c24dbfbc1f14c40c4c2338",
            "value": "tokenizer_config.json:100%"
          }
        },
        "b5cc1d12347c4e8b9d843c6502d6abe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b695582899e24574afd9291efbc04a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1adf42b0a4c4794bd46d31cc86cf708",
            "placeholder": "",
            "style": "IPY_MODEL_8b2c9293259f4400bfd484117e0e350e",
            "value": "480/480[00:00&lt;00:00,26.8kB/s]"
          }
        },
        "b7bcde5746bf42d3b4f7ef5bbdc2f09a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98c211278daf4ef89ac703ffc7a3f537",
              "IPY_MODEL_5c55c10cda124c02b0107d32c27ea06b",
              "IPY_MODEL_bf2d117f68374611b2f17f569dbd27ac"
            ],
            "layout": "IPY_MODEL_2fdc012519f14375b2bf3cde5063d428"
          }
        },
        "ba2915bcbb014d98af038d8b98a13fa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f52f8e8a44c246d6992794922b07f7a9",
            "placeholder": "",
            "style": "IPY_MODEL_55bf832e97b147ae9bb036e07b2f59c3",
            "value": "25.0/25.0[00:00&lt;00:00,1.54kB/s]"
          }
        },
        "bbe7bf5f35a64273a3fcd4d270b2a038": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be05ec628a204ab8a4576f56bd43f941": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf2d117f68374611b2f17f569dbd27ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4839692b8f944b569cf79e1a908c61c4",
            "placeholder": "",
            "style": "IPY_MODEL_c84cbc24dcc7401aa64d0cd8e7d08e60",
            "value": "4.20k/4.20k[00:00&lt;00:00,214kB/s]"
          }
        },
        "c1666b0761ee4e329ed6351e44eff1ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7268f97a65e4f9598fc771b093ba1d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a79c4c66d58d46d39f8c47eca7012de1",
              "IPY_MODEL_ff30053daaf34af2adedab95c182017f",
              "IPY_MODEL_b695582899e24574afd9291efbc04a3c"
            ],
            "layout": "IPY_MODEL_e7c91059d97345dbb343e807055a515b"
          }
        },
        "c84cbc24dcc7401aa64d0cd8e7d08e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d03df5cc5edb49b795c8c3597d3809e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b2a2c7cecd243e19af31556fbf43d46",
            "placeholder": "",
            "style": "IPY_MODEL_1793d0fd51154ef5b24af7a7bcd789a5",
            "value": "1.36M/1.36M[00:00&lt;00:00,14.9MB/s]"
          }
        },
        "d84064d3ec0e40759c78a3750bd8d30f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e02894ab20194ffcac7d48c6b400551f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1adf42b0a4c4794bd46d31cc86cf708": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7c91059d97345dbb343e807055a515b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8c6e33cc6e24313b94f986277893000": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f239b67772ec476ca31d6369930ce534": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f52f8e8a44c246d6992794922b07f7a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f85fc5140a0c45ff8ad4553aeded38bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_039408981637400fa52fda71be866d5f",
            "placeholder": "",
            "style": "IPY_MODEL_e8c6e33cc6e24313b94f986277893000",
            "value": "456k/456k[00:00&lt;00:00,8.57MB/s]"
          }
        },
        "f9bc15b7a7874e3487f1f92d36cd0d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4297cf09052f458796c7c95c89c6f762",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1cf145481c7f4a9abfbc90f787cdf49a",
            "value": 898823
          }
        },
        "ff30053daaf34af2adedab95c182017f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be05ec628a204ab8a4576f56bd43f941",
            "max": 480,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b70e3072faa4e919b70ae4be36a301b",
            "value": 480
          }
        },
        "ff9178ea9c464c38aa0729083c3fd257": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e02894ab20194ffcac7d48c6b400551f",
            "placeholder": "",
            "style": "IPY_MODEL_6df45a7322cc483db8ef616d8c6bd69b",
            "value": "model.safetensors:100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}